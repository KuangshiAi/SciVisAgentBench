"""
HTML template generator for evaluation reports.
"""

import json
from typing import Dict, List, Any


def generate_html_template(
    agent_name: str,
    config: Dict[str, Any],
    results: List[Dict[str, Any]],
    yaml_cases: Dict[str, Dict[str, Any]],
    summary: Dict[str, Any],
    token_usage_map: Dict[str, Dict[str, Any]],
    generated_time: str
) -> str:
    """Generate the full HTML report."""

    # Generate summary section
    summary_html = generate_summary_section(agent_name, config, summary, generated_time)

    # Generate case results
    cases_html = generate_cases_section(results, yaml_cases, token_usage_map)

    # Combine into full HTML
    html = f"""<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Evaluation Report - {agent_name}</title>
    <style>
        {get_css_styles()}
    </style>
</head>
<body>
    <div class="container">
        <header class="header">
            <h1>üéØ SciVisAgentBench Evaluation Report</h1>
            <div class="header-meta">
                <span class="agent-name">{agent_name}</span>
                <span class="timestamp">Generated: {generated_time}</span>
            </div>
        </header>

        {summary_html}

        <nav class="case-nav">
            <h3>Jump to Case:</h3>
            <div class="case-links">
                {generate_case_links(results)}
            </div>
        </nav>

        {cases_html}

        <footer class="footer">
            <p>Generated by SciVisAgentBench Evaluation Reporter</p>
            <p>Timestamp: {generated_time}</p>
        </footer>
    </div>

    <script>
        {get_javascript()}
    </script>
</body>
</html>
"""

    return html


def get_css_styles() -> str:
    """Return CSS styles for the report."""
    return """
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, 'Helvetica Neue', Arial, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: #333;
            line-height: 1.6;
            padding: 20px;
        }

        .container {
            max-width: 1400px;
            margin: 0 auto;
            background: white;
            border-radius: 12px;
            box-shadow: 0 20px 60px rgba(0,0,0,0.3);
            overflow: hidden;
        }

        .header {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 40px;
            text-align: center;
        }

        .header h1 {
            font-size: 2.5em;
            margin-bottom: 15px;
            font-weight: 700;
        }

        .header-meta {
            display: flex;
            justify-content: center;
            gap: 30px;
            font-size: 1.1em;
            opacity: 0.95;
        }

        .agent-name {
            background: rgba(255, 255, 255, 0.2);
            padding: 8px 20px;
            border-radius: 20px;
            font-weight: 600;
        }

        .timestamp {
            font-size: 0.9em;
            opacity: 0.8;
        }

        .summary {
            padding: 40px;
            background: #f8f9fa;
            border-bottom: 3px solid #667eea;
        }

        .summary h2 {
            color: #667eea;
            margin-bottom: 25px;
            font-size: 2em;
        }

        .summary-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
            gap: 20px;
            margin-bottom: 30px;
        }

        .summary-card {
            background: white;
            padding: 25px;
            border-radius: 10px;
            box-shadow: 0 4px 6px rgba(0,0,0,0.1);
            transition: transform 0.3s, box-shadow 0.3s;
        }

        .summary-card:hover {
            transform: translateY(-5px);
            box-shadow: 0 8px 15px rgba(0,0,0,0.2);
        }

        .summary-card h3 {
            color: #667eea;
            font-size: 0.9em;
            text-transform: uppercase;
            letter-spacing: 1px;
            margin-bottom: 10px;
        }

        .summary-card .value {
            font-size: 2.5em;
            font-weight: 700;
            color: #333;
        }

        .summary-card .sub-value {
            font-size: 0.9em;
            color: #666;
            margin-top: 5px;
        }

        .score-excellent { color: #10b981; }
        .score-good { color: #3b82f6; }
        .score-fair { color: #f59e0b; }
        .score-poor { color: #ef4444; }

        .config-info {
            background: white;
            padding: 20px;
            border-radius: 10px;
            margin-top: 20px;
        }

        .config-info h3 {
            color: #667eea;
            margin-bottom: 15px;
        }

        .config-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 15px;
        }

        .config-item {
            display: flex;
            flex-direction: column;
        }

        .config-item label {
            font-weight: 600;
            color: #666;
            font-size: 0.85em;
            margin-bottom: 5px;
        }

        .config-item value {
            font-size: 1em;
            color: #333;
            font-family: 'Monaco', 'Courier New', monospace;
        }

        .case-nav {
            padding: 30px 40px;
            background: white;
            border-bottom: 2px solid #e5e7eb;
            position: sticky;
            top: 0;
            z-index: 100;
            box-shadow: 0 2px 8px rgba(0,0,0,0.1);
        }

        .case-nav h3 {
            color: #667eea;
            margin-bottom: 15px;
        }

        .case-links {
            display: flex;
            flex-wrap: wrap;
            gap: 10px;
        }

        .case-link {
            padding: 8px 16px;
            background: #f3f4f6;
            border-radius: 6px;
            text-decoration: none;
            color: #667eea;
            font-weight: 500;
            transition: all 0.3s;
            font-size: 0.9em;
        }

        .case-link:hover {
            background: #667eea;
            color: white;
            transform: translateY(-2px);
        }

        .case-section {
            padding: 40px;
            border-bottom: 3px solid #f3f4f6;
        }

        .case-section:last-child {
            border-bottom: none;
        }

        .case-header {
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin-bottom: 25px;
            padding-bottom: 15px;
            border-bottom: 3px solid #667eea;
        }

        .case-title-group {
            display: flex;
            align-items: center;
            gap: 15px;
        }

        .case-title {
            font-size: 1.8em;
            color: #333;
            font-weight: 700;
        }

        .status-badge {
            padding: 6px 15px;
            border-radius: 20px;
            font-size: 0.7em;
            font-weight: 600;
            letter-spacing: 0.5px;
        }

        .status-failed {
            background: #fee2e2;
            color: #dc2626;
        }

        .status-warning {
            background: #fef3c7;
            color: #d97706;
        }

        .case-score {
            font-size: 1.5em;
            font-weight: 700;
            padding: 10px 25px;
            border-radius: 50px;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
        }

        .case-content {
            display: grid;
            gap: 30px;
        }

        .section-box {
            background: #f8f9fa;
            padding: 25px;
            border-radius: 10px;
            border-left: 4px solid #667eea;
        }

        .section-box h3 {
            color: #667eea;
            margin-bottom: 15px;
            font-size: 1.3em;
        }

        .task-description {
            background: white;
            padding: 20px;
            border-radius: 8px;
            white-space: pre-wrap;
            font-family: 'Monaco', 'Courier New', monospace;
            font-size: 0.9em;
            line-height: 1.6;
            border: 1px solid #e5e7eb;
        }

        .image-comparison {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
            gap: 20px;
        }

        .image-box {
            background: white;
            padding: 15px;
            border-radius: 10px;
            box-shadow: 0 2px 8px rgba(0,0,0,0.1);
        }

        .image-box h4 {
            color: #667eea;
            margin-bottom: 10px;
            font-size: 1.1em;
        }

        .image-box img {
            width: 100%;
            height: auto;
            border-radius: 8px;
            border: 2px solid #e5e7eb;
        }

        .image-box .no-image {
            width: 100%;
            height: 300px;
            background: #f3f4f6;
            border-radius: 8px;
            display: flex;
            align-items: center;
            justify-content: center;
            color: #9ca3af;
            font-size: 1.1em;
        }

        .rubric-scores {
            display: grid;
            gap: 15px;
        }

        .rubric-item {
            background: white;
            padding: 20px;
            border-radius: 8px;
            border-left: 4px solid #667eea;
        }

        .rubric-header {
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin-bottom: 10px;
        }

        .rubric-title {
            font-weight: 700;
            color: #333;
            flex: 1;
        }

        .rubric-score {
            font-size: 1.3em;
            font-weight: 700;
            padding: 5px 15px;
            border-radius: 20px;
            background: #667eea;
            color: white;
        }

        .rubric-criterion {
            background: #f8f9fa;
            padding: 12px;
            border-radius: 6px;
            margin-top: 10px;
            color: #333;
            line-height: 1.6;
            font-style: italic;
        }

        .rubric-criterion strong {
            color: #667eea;
            font-style: normal;
        }

        .rubric-explanation {
            color: #666;
            line-height: 1.6;
            margin-top: 10px;
            padding: 12px;
            background: white;
            border-radius: 6px;
            border-left: 3px solid #667eea;
        }

        .rubric-explanation strong {
            color: #764ba2;
        }

        .metrics-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 15px;
        }

        .metric-box {
            background: white;
            padding: 20px;
            border-radius: 8px;
            text-align: center;
            box-shadow: 0 2px 8px rgba(0,0,0,0.1);
        }

        .metric-label {
            font-size: 0.85em;
            color: #666;
            text-transform: uppercase;
            letter-spacing: 1px;
            margin-bottom: 8px;
        }

        .metric-value {
            font-size: 1.8em;
            font-weight: 700;
            color: #667eea;
        }

        .metric-subvalue {
            font-size: 0.9em;
            color: #999;
            margin-top: 5px;
        }

        .code-similarity {
            background: white;
            padding: 20px;
            border-radius: 8px;
            border: 2px solid #667eea;
        }

        .code-similarity h4 {
            color: #667eea;
            margin-bottom: 15px;
        }

        .code-sim-score {
            font-size: 2em;
            font-weight: 700;
            color: #667eea;
            margin-bottom: 10px;
        }

        .code-sim-details {
            color: #666;
            font-size: 0.9em;
        }

        .expandable {
            cursor: pointer;
            user-select: none;
        }

        .expandable::before {
            content: '‚ñº ';
            display: inline-block;
            transition: transform 0.3s;
        }

        .expandable.collapsed::before {
            transform: rotate(-90deg);
        }

        .expandable-content {
            margin-top: 15px;
            overflow: hidden;
            transition: max-height 0.3s ease-out;
        }

        .expandable-content.collapsed {
            max-height: 0;
            margin-top: 0;
        }

        .footer {
            background: #f8f9fa;
            padding: 30px;
            text-align: center;
            color: #666;
            font-size: 0.9em;
        }

        .footer p {
            margin: 5px 0;
        }

        @media (max-width: 768px) {
            .header h1 {
                font-size: 1.8em;
            }

            .summary-grid {
                grid-template-columns: 1fr;
            }

            .image-comparison {
                grid-template-columns: 1fr;
            }

            .case-header {
                flex-direction: column;
                align-items: flex-start;
                gap: 15px;
            }

            .case-title-group {
                flex-direction: column;
                align-items: flex-start;
                gap: 10px;
            }

            .case-title {
                font-size: 1.5em;
            }
        }
    """


def generate_summary_section(
    agent_name: str,
    config: Dict[str, Any],
    summary: Dict[str, Any],
    generated_time: str
) -> str:
    """Generate the summary statistics section."""

    # Determine score class
    overall_pct = summary['overall_percentage']
    if overall_pct >= 90:
        score_class = 'score-excellent'
    elif overall_pct >= 75:
        score_class = 'score-good'
    elif overall_pct >= 60:
        score_class = 'score-fair'
    else:
        score_class = 'score-poor'

    # Format scaled PSNR, SSIM, LPIPS
    completion_rate = summary['completion_rate']
    psnr_count = summary.get('psnr_count', 0)

    psnr_scaled_text = f"{summary['psnr_scaled']:.2f} dB" if summary['psnr_scaled'] is not None else "N/A"
    ssim_scaled_text = f"{summary['ssim_scaled']:.4f}" if summary['ssim_scaled'] is not None else "N/A"
    lpips_scaled_text = f"{summary['lpips_scaled']:.4f}" if summary['lpips_scaled'] is not None else "N/A"

    # Add note about excluded infinite PSNR cases
    psnr_note = f" ({psnr_count}/{summary['completed_cases']} valid)" if psnr_count < summary['completed_cases'] else ""

    return f"""
        <section class="summary">
            <h2>üìä Overall Performance</h2>

            <div class="summary-grid">
                <div class="summary-card">
                    <h3>Overall Score</h3>
                    <div class="value {score_class}">
                        {summary['overall_percentage']:.1f}%
                    </div>
                    <div class="sub-value">
                        {summary['total_score']}/{summary['max_score']} Points
                    </div>
                </div>

                <div class="summary-card">
                    <h3>Test Cases</h3>
                    <div class="value">
                        {summary['completed_cases']}/{summary['total_cases']}
                    </div>
                    <div class="sub-value">
                        Completed Successfully
                    </div>
                </div>

                <div class="summary-card">
                    <h3>Avg Vision Score</h3>
                    <div class="value">
                        {summary['avg_vision_score']:.1f}%
                    </div>
                    <div class="sub-value">
                        Visualization Quality
                    </div>
                </div>

                <div class="summary-card">
                    <h3>Avg Code Similarity</h3>
                    <div class="value">
                        {summary['avg_code_score']:.1f}%
                    </div>
                    <div class="sub-value">
                        Code Quality Match
                    </div>
                </div>

                <div class="summary-card">
                    <h3>PSNR (Scaled)</h3>
                    <div class="value">
                        {psnr_scaled_text}
                    </div>
                    <div class="sub-value">
                        Peak SNR{psnr_note}
                    </div>
                </div>

                <div class="summary-card">
                    <h3>SSIM (Scaled)</h3>
                    <div class="value">
                        {ssim_scaled_text}
                    </div>
                    <div class="sub-value">
                        Structural Similarity
                    </div>
                </div>

                <div class="summary-card">
                    <h3>LPIPS (Scaled)</h3>
                    <div class="value">
                        {lpips_scaled_text}
                    </div>
                    <div class="sub-value">
                        Perceptual Distance
                    </div>
                </div>

                <div class="summary-card">
                    <h3>Completion Rate</h3>
                    <div class="value">
                        {completion_rate * 100:.1f}%
                    </div>
                    <div class="sub-value">
                        Tasks completed
                    </div>
                </div>
            </div>

            <div style="margin-top: 20px; padding: 15px; background: #f0f9ff; border-radius: 8px; border-left: 4px solid #667eea;">
                <h4 style="color: #667eea; margin-bottom: 10px;">‚ÑπÔ∏è About Scaled Metrics</h4>
                <p style="color: #666; line-height: 1.6; margin: 0;">
                    <strong>Scaled metrics</strong> account for completion rate to enable fair comparison across different evaluation modes.
                    Formula: <em>PSNR<sub>scaled</sub> = (completed_cases / total_cases) √ó avg(PSNR)</em>,
                    <em>SSIM<sub>scaled</sub> = (completed_cases / total_cases) √ó avg(SSIM)</em>,
                    <em>LPIPS<sub>scaled</sub> = 1.0 - (completed_cases / total_cases) √ó (1.0 - avg(LPIPS))</em>.
                    Cases with infinite PSNR (perfect match) are excluded from PSNR calculation.
                </p>
            </div>

            <div class="config-info">
                <h3>üîß Configuration</h3>
                <div class="config-grid">
                    <div class="config-item">
                        <label>Provider</label>
                        <value>{config.get('provider', 'N/A')}</value>
                    </div>
                    <div class="config-item">
                        <label>Model</label>
                        <value>{config.get('model', 'N/A')}</value>
                    </div>
                    <div class="config-item">
                        <label>Base URL</label>
                        <value>{config.get('base_url', 'N/A')}</value>
                    </div>
                    <div class="config-item">
                        <label>Input Price</label>
                        <value>{config.get('price', {}).get('input_per_1m_tokens', 'N/A')}</value>
                    </div>
                    <div class="config-item">
                        <label>Output Price</label>
                        <value>{config.get('price', {}).get('output_per_1m_tokens', 'N/A')}</value>
                    </div>
                </div>
            </div>
        </section>
    """


def generate_case_links(results: List[Dict[str, Any]]) -> str:
    """Generate navigation links for all cases."""
    links = []
    for result in results:
        case_name = result.get('case_name', 'unknown')
        links.append(f'<a href="#{case_name}" class="case-link">{case_name}</a>')
    return '\n'.join(links)


def generate_cases_section(
    results: List[Dict[str, Any]],
    yaml_cases: Dict[str, Dict[str, Any]],
    token_usage_map: Dict[str, Dict[str, Any]]
) -> str:
    """Generate individual case sections."""
    sections = []

    for result in results:
        case_name = result.get('case_name', 'unknown')
        yaml_data = yaml_cases.get(case_name, {})
        token_usage = token_usage_map.get(case_name, {})

        sections.append(generate_case_section(result, yaml_data, token_usage))

    return '\n'.join(sections)


def generate_case_section(result: Dict[str, Any], yaml_data: Dict[str, Any], token_usage: Dict[str, Any]) -> str:
    """Generate a single case section."""
    case_name = result.get('case_name', 'unknown')
    eval_data = result.get('evaluation', {})

    # Get overall score
    scores = eval_data.get('scores', {})
    total_score = scores.get('total_score', 0)
    max_score = scores.get('max_possible_score', 1)
    percentage = scores.get('percentage', 0)

    # Determine status
    eval_status = eval_data.get('status', 'unknown')
    status_badge = ''
    if eval_status == 'failed':
        status_badge = '<span class="status-badge status-failed">‚ùå FAILED</span>'
    elif eval_status == 'completed' and percentage < 50:
        status_badge = '<span class="status-badge status-warning">‚ö†Ô∏è LOW SCORE</span>'

    # Get task description
    task_desc = yaml_data.get('vars', {}).get('question', 'No description available')

    # Generate rubric scores section
    rubric_html = generate_rubric_section(eval_data)

    # Generate metrics section (pass token_usage from test results)
    metrics_html = generate_metrics_section(eval_data, result, token_usage)

    # Generate image comparison
    images_html = generate_image_section(case_name)

    return f"""
        <section class="case-section" id="{case_name}">
            <div class="case-header">
                <div class="case-title-group">
                    <h2 class="case-title">üìù {case_name}</h2>
                    {status_badge}
                </div>
                <div class="case-score">{total_score}/{max_score} ({percentage:.1f}%)</div>
            </div>

            <div class="case-content">
                <div class="section-box">
                    <h3>üìã Task Description</h3>
                    <div class="task-description">{task_desc}</div>
                </div>

                {images_html}

                {rubric_html}

                {metrics_html}
            </div>
        </section>
    """


def generate_image_section(case_name: str) -> str:
    """Generate image comparison section."""
    return f"""
        <div class="section-box">
            <h3>üñºÔ∏è Visualization Comparison</h3>
            <div class="image-comparison">
                <div class="image-box">
                    <h4>Ground Truth</h4>
                    <img src="images/{case_name}_gt.png" alt="Ground Truth" onerror="this.parentElement.innerHTML='<div class=\\'no-image\\'>Image not available</div>'">
                </div>
                <div class="image-box">
                    <h4>Agent Result</h4>
                    <img src="images/{case_name}_result.png" alt="Result" onerror="this.parentElement.innerHTML='<div class=\\'no-image\\'>Image not available</div>'">
                </div>
            </div>
        </div>
    """


def generate_rubric_section(eval_data: Dict[str, Any]) -> str:
    """Generate rubric evaluation scores section."""
    subtype_results = eval_data.get('subtype_results', {})

    if 'vision' not in subtype_results:
        return ""

    vision_data = subtype_results['vision']
    rubric = vision_data.get('rubric', '')
    detailed_scores = vision_data.get('detailed_scores', {})
    viz_quality = detailed_scores.get('visualization_quality', {})

    llm_response = viz_quality.get('llm_raw_response', {})

    # Parse the original rubric criteria
    rubric_criteria = []
    if rubric:
        # Split rubric by numbered goals (e.g., "1. ", "2. ")
        import re
        criteria_parts = re.split(r'\n\s*\d+\.\s+', rubric)
        # Remove empty first element and clean up whitespace
        rubric_criteria = [c.strip() for c in criteria_parts if c.strip()]

    # Extract individual goal scores
    rubric_items = []
    goals_count = vision_data.get('goals_count', 0)

    # Get max scores for display
    viz_quality_max = viz_quality.get('max_score', goals_count * 10)

    for i in range(1, goals_count + 1):
        goal_score = llm_response.get(f'goal_{i}_score', 0)
        goal_explanation = llm_response.get(f'goal_{i}_explanation', '')

        # Get the original rubric criterion for this goal
        criterion = rubric_criteria[i-1] if i-1 < len(rubric_criteria) else f'Goal {i} criterion not available'

        # If no explanation, show why (failed or not evaluated)
        if not goal_explanation:
            eval_status = vision_data.get('status', 'unknown')
            if eval_status == 'failed':
                goal_explanation = '<em style="color: #dc2626;">Evaluation failed - no assessment available</em>'
            else:
                goal_explanation = '<em style="color: #9ca3af;">Not evaluated</em>'

        rubric_items.append(f"""
            <div class="rubric-item">
                <div class="rubric-header">
                    <div class="rubric-title">Goal {i}</div>
                    <div class="rubric-score">{goal_score}/10</div>
                </div>
                <div class="rubric-criterion">
                    <strong>Criterion:</strong> {criterion}
                </div>
                <div class="rubric-explanation">
                    <strong>Judge's Assessment:</strong> {goal_explanation}
                </div>
            </div>
        """)

    # Overall assessment
    overall_explanation = llm_response.get('overall_explanation', '')
    if not overall_explanation:
        eval_status = vision_data.get('status', 'unknown')
        if eval_status == 'failed':
            overall_explanation = '<em style="color: #dc2626;">Evaluation failed - no overall assessment available</em>'
        else:
            overall_explanation = '<em style="color: #9ca3af;">No overall explanation available</em>'

    # Show total score breakdown
    viz_score = viz_quality.get('score', 0)
    score_summary = f"""
        <div style="margin-top: 20px; padding: 15px; background: #f8f9fa; border-radius: 8px; border-left: 4px solid #667eea;">
            <h4 style="color: #667eea; margin-bottom: 10px;">Score Summary</h4>
            <div style="display: grid; grid-template-columns: repeat(auto-fit, minmax(150px, 1fr)); gap: 10px; margin-bottom: 10px;">
                <div style="background: white; padding: 10px; border-radius: 6px; text-align: center;">
                    <div style="font-size: 0.85em; color: #666; margin-bottom: 5px;">Total Score</div>
                    <div style="font-size: 1.5em; font-weight: 700; color: #667eea;">{viz_score}/{viz_quality_max}</div>
                </div>
                <div style="background: white; padding: 10px; border-radius: 6px; text-align: center;">
                    <div style="font-size: 0.85em; color: #666; margin-bottom: 5px;">Goals</div>
                    <div style="font-size: 1.5em; font-weight: 700; color: #667eea;">{goals_count}</div>
                </div>
                <div style="background: white; padding: 10px; border-radius: 6px; text-align: center;">
                    <div style="font-size: 0.85em; color: #666; margin-bottom: 5px;">Points/Goal</div>
                    <div style="font-size: 1.5em; font-weight: 700; color: #667eea;">10</div>
                </div>
            </div>
        </div>
    """

    return f"""
        <div class="section-box">
            <h3 class="expandable">üìè Vision Evaluation Rubrics</h3>
            <div class="expandable-content">
                {score_summary}
                <div class="rubric-scores" style="margin-top: 15px;">
                    {' '.join(rubric_items)}
                </div>
                <div style="margin-top: 20px; padding: 15px; background: white; border-radius: 8px;">
                    <h4 style="color: #667eea; margin-bottom: 10px;">Overall Assessment</h4>
                    <p style="color: #666;">{overall_explanation}</p>
                </div>
            </div>
        </div>
    """


def generate_metrics_section(eval_data: Dict[str, Any], result: Dict[str, Any], token_usage: Dict[str, Any]) -> str:
    """Generate detailed metrics section."""
    subtype_results = eval_data.get('subtype_results', {})

    metrics = []

    # Vision metrics
    if 'vision' in subtype_results:
        vision_data = subtype_results['vision']
        scores = vision_data.get('scores', {})
        image_metrics = vision_data.get('image_metrics', {}).get('averaged_metrics', {})
        detailed = vision_data.get('detailed_scores', {})

        metrics.append(f"""
            <div class="metric-box">
                <div class="metric-label">Visualization Quality</div>
                <div class="metric-value">{scores.get('visualization_quality', 0)}/{vision_data.get('goals_count', 0) * 10}</div>
            </div>
        """)

        metrics.append(f"""
            <div class="metric-box">
                <div class="metric-label">Output Generation</div>
                <div class="metric-value">{scores.get('output_generation', 0)}/5</div>
            </div>
        """)

        metrics.append(f"""
            <div class="metric-box">
                <div class="metric-label">Efficiency</div>
                <div class="metric-value">{scores.get('efficiency', 0)}/10</div>
                <div class="metric-subvalue">
                    {detailed.get('efficiency', {}).get('execution_time', {}).get('explanation', '')}
                </div>
            </div>
        """)

        # Image quality metrics
        if image_metrics.get('psnr') is not None:
            import math
            psnr = image_metrics['psnr']
            psnr_display = "‚àû dB" if math.isinf(psnr) else f"{psnr:.2f} dB"
            metrics.append(f"""
                <div class="metric-box">
                    <div class="metric-label">PSNR</div>
                    <div class="metric-value">{psnr_display}</div>
                </div>
            """)

        if image_metrics.get('ssim') is not None:
            metrics.append(f"""
                <div class="metric-box">
                    <div class="metric-label">SSIM</div>
                    <div class="metric-value">{image_metrics['ssim']:.4f}</div>
                </div>
            """)

        if image_metrics.get('lpips') is not None:
            metrics.append(f"""
                <div class="metric-box">
                    <div class="metric-label">LPIPS</div>
                    <div class="metric-value">{image_metrics['lpips']:.4f}</div>
                </div>
            """)

    # Token usage - prioritize parameter from test results, fallback to result data
    # The token_usage parameter comes from test_results/pvpython/test_result_*.json
    tokens = token_usage if token_usage else {}
    if not tokens:
        # Fallback: try root level and metadata from centralized result
        tokens = result.get('token_usage', {})
        if not tokens:
            metadata = result.get('metadata', {})
            tokens = metadata.get('token_usage', {})

    if tokens and tokens.get('total_tokens', 0) > 0:
        metrics.append(f"""
            <div class="metric-box">
                <div class="metric-label">Input Tokens</div>
                <div class="metric-value">{tokens.get('input_tokens', 0):,}</div>
            </div>
        """)

        metrics.append(f"""
            <div class="metric-box">
                <div class="metric-label">Output Tokens</div>
                <div class="metric-value">{tokens.get('output_tokens', 0):,}</div>
            </div>
        """)

        metrics.append(f"""
            <div class="metric-box">
                <div class="metric-label">Total Tokens</div>
                <div class="metric-value">{tokens.get('total_tokens', 0):,}</div>
            </div>
        """)

    metrics_grid = f'<div class="metrics-grid">{"".join(metrics)}</div>'

    # Code similarity section
    code_html = ""
    if 'code' in subtype_results:
        code_data = subtype_results['code']
        code_scores = code_data.get('scores', {})
        code_details = code_data.get('detailed_scores', {}).get('code_similarity', {})

        code_html = f"""
            <div class="code-similarity">
                <h4>üíª Code Similarity</h4>
                <div class="code-sim-score">{code_scores.get('code_similarity', 0)}/10</div>
                <div class="code-sim-details">
                    {code_details.get('explanation', '')}
                </div>
                <div style="margin-top: 15px; font-size: 0.85em; color: #999;">
                    <div>Ground Truth: {code_data.get('gs_file', 'N/A')}</div>
                    <div>Result File: {code_data.get('rs_file', 'N/A')}</div>
                </div>
            </div>
        """

    return f"""
        <div class="section-box">
            <h3>üìä Detailed Metrics</h3>
            {metrics_grid}
            {code_html}
        </div>
    """


def get_javascript() -> str:
    """Return JavaScript for interactive features."""
    return """
        // Expandable sections
        document.querySelectorAll('.expandable').forEach(element => {
            element.addEventListener('click', function() {
                this.classList.toggle('collapsed');
                const content = this.nextElementSibling;
                if (content && content.classList.contains('expandable-content')) {
                    content.classList.toggle('collapsed');
                }
            });
        });

        // Smooth scrolling for anchor links
        document.querySelectorAll('a[href^="#"]').forEach(anchor => {
            anchor.addEventListener('click', function (e) {
                e.preventDefault();
                const target = document.querySelector(this.getAttribute('href'));
                if (target) {
                    target.scrollIntoView({
                        behavior: 'smooth',
                        block: 'start'
                    });
                }
            });
        });

        // Initialize expandable sections as collapsed
        document.querySelectorAll('.expandable-content').forEach(content => {
            content.style.maxHeight = content.scrollHeight + 'px';
        });

        console.log('üìä Evaluation Report Loaded');
    """
