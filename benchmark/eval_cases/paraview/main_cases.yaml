# Comprehensive Test Cases for SciVisAgentBench Main Tasks
# This test evaluates the ability to complete specific visualization tasks
# with detailed requirements and evaluation criteria

# 1. Bonsai Dataset
- vars:
    question: |
        Task:

        Load the bonsai dataset from "bonsai/data/bonsai_256x256x256_uint8.raw", the information about this dataset:
        Bonsai (Scalar)
        Data Scalar Type: unsigned char
        Data Byte Order: little Endian
        Data Spacing: 1x1x1
        Data Extent: 256x256x256

        Then visualize it with volume rendering, modify the transfer function and reach the visualization goal as: "A potted tree with brown pot silver branch and golden leaves."

        Please think step by step and make sure to fulfill all the visualization goals mentioned above.

        Finally, save the paraview state as "bonsai/results/{agent_mode}/bonsai.pvsm"
  assert:
    - type: llm-rubric
      subtype: vision
      value: |
          1. Brown Pot Visualization: Does the result show the pot portion in brown color?

          2. Silver Branch Visualization: Does the result show the branch/trunk portion in silver color?

          3. Golden Leaves Visualization: Does the result show the leaves portion in golden color?

# 2. Carp Dataset
- vars:
    question: |
        Task:

        Load the carp dataset from "carp/data/carp_256x256x512_uint16.raw", the information about this dataset:
        Carp (Scalar)
        Data Scalar Type: unsigned short
        Data Byte Order: little Endian
        Data Spacing: 0.78125x0.390625x1
        Data Extent: 256x256x512

        Instructions:

        1. Load the dataset into ParaView.

        2. Apply volume rendering to visualize the carp skeleton.

        3. Adjust the transfer function to highlight only the bony structures in an X-ray style (suppressing soft tissue).

        4. Optimize the viewpoint to display the full skeleton, ensuring the head, spine, and fins are all clearly visible in a single frame.

        5. Analyze the visualization and answer the following questions:

        Q1: Which of the following options correctly describes the fins visible in the carp skeleton visualization?
        A. 5 fins: 1 dorsal, 2 pectoral, 2 pelvic
        B. 6 fins: 1 dorsal, 2 pectoral, 2 pelvic, 1 caudal
        C. 7 fins: 1 dorsal, 2 pectoral, 2 pelvic, 1 anal, 1 caudal
        D. 8 fins: 2 dorsal, 2 pectoral, 2 pelvic, 1 anal, 1 caudal

        Q2: Based on the visualization, what is the approximate ratio of skull length to total body length?
        A. ~15%
        B. ~22%
        C. ~30%
        D. ~40%

        6. Save your work:
        Save the ParaView state as "carp/results/{agent_mode}/carp.pvsm".
        Save the answers to the analysis questions in plain text as "carp/results/{agent_mode}/answers.txt".
  assert:
    - type: llm-rubric
      subtype: vision
      value: |
          1. Bone Isolation: Are the bones clearly visible while soft tissue and background are suppressed? Thin fin rays should be distinguishable without major loss.

          2. Viewpoint Selection: Does the chosen viewpoint display the entire carp skeleton (head, spine, ribs, fins, tail) without critical occlusion?

          3. X-ray Appearance: Does the visualization resemble an X-ray (monochrome or grayscale, transparent look, consistent lighting)?

          4. Correct Data Setup: Was the dataset loaded with proper spacing (0.78125x0.390625x1.0)? The carp skeleton should appear in its correct proportions without distortion (i.e., the fish shape looks anatomically normal).
    - type: llm-rubric
      subtype: text
      value: |
          1. Q1 correct answer: C. 7 fins: 1 dorsal, 2 pectoral, 2 pelvic, 1 anal, 1 caudal

          2. Q2 correct answer: B. ~22%

# 3. Chameleon Dataset (VolVis)
- vars:
    question: |
        Task:

        Load the chameleon dataset from "chameleon_volvis/data/chameleon_volvis_256x256x270_float32.raw", the information about this dataset:
        chameleon (Scalar)
        Data Scalar Type: float
        Data Byte Order: little Endian
        Data Extent: 256x256x270
        Number of Scalar Components: 1
        Data loading is very important, make sure you correctly load the dataset according to their features.

        Apply the volume rendering to visualize the chameleon dataset

        Adjust the transfer function to highlight the bony structures and skin in an X-ray style.

        Adjust the camera position and focus on the head part of the chameleon

        Please think step by step and make sure to fulfill all the visualization goals mentioned above.

        Finally, save the paraview state as "chameleon_volvis/results/{agent_mode}/chameleon_volvis.pvsm"
  assert:
    - type: llm-rubric
      subtype: vision
      value: |
          1. Overall Visualization Goal: Does the result present a clean, X-ray–style volume rendering where the chameleon's bony structures are clearly emphasized and soft tissue is faint but discernible?

          2. Data Loading Correctness: Is the RAW volume loaded with the specified metadata (float32, little-endian, 256×256×270, 1 component) so that the histogram looks reasonable and the anatomy is not flipped or distorted?

          3. Transfer Function Quality: Does the grayscale transfer function make low-intensity tissue mostly transparent while assigning higher opacity to bones/skin ridges, yielding good depth cues without over-saturation or banding?

          4. Camera & Framing: Is the camera positioned and zoomed to focus on the chameleon's head, keeping it sharply framed (no clipping), with a stable viewpoint that highlights key anatomical details?

# 4. Engine Dataset
- vars:
    question: |
        Task:

        Load the vortex dataset from "engine/data/engine_256x256x128_uint8.raw", the information about this dataset:
        engine (Scalar)
        Data Scalar Type: float
        Data Byte Order: little Endian
        Data Extent: 256x256x128
        Number of Scalar Components: 1

        Instructions:

        1. Load the dataset into ParaView.

        2. Apply the volume rendering to visualize the engine dataset

        3. Adjust the transfer function, let the outer part more transparent and the inner part more solid. Use light blue for the outer part and orange for the inner part.

        4. Save your work:
        Save the ParaView state as "engine/results/{agent_mode}/engine.pvsm".
  assert:
    - type: llm-rubric
      subtype: vision
      value: |
          1. Overall Visualization Goal: How well does the result use volume rendering to clearly present the internal and external structures of the engine dataset?

          2. Structural Clarity: Does the visualization emphasize depth so that the outer layers do not obscure the inner structures?

          3. Transfer Function Transparency: Is the outer region rendered with higher transparency and the inner region more solid, achieving a clear layering effect?

          4. Transfer Function Color Mapping: Are colors correctly assigned so that the outer part is light blue and the inner part is orange, enhancing structural contrast?

# 5. Solar Plume Dataset
- vars:
    question: |
        Task:

        Load the tornado dataset from "solar-plume/data/solar-plume_126x126x512_float32_scalar3.raw", the information about this dataset:
        solar-plume (Vector)
        Data Scalar Type: float
        Data Byte Order: little Endian
        Data Extent: 126x126x512
        Number of Scalar Components: 3
        Data loading is very important, make sure you correctly load the dataset according to their features.

        Add a "stream tracer" filter under the tornado data to display streamline, set the "Seed type" to "Point Cloud" and set the center of point cloud to 3D position [50, 50, 320] with a radius 30, then hide the point cloud sphere.

        Add a "tube" filter under the "stream tracer" filter to enhance the streamline visualization. Set the radius to 0.5. In the pipeline browser panel, hide everything except the "tube" filter. 


        Please think step by step and make sure to fulfill all the visualization goals mentioned above.

        Finally, save the paraview state as "solar-plume/results/{agent_mode}/solar-plume.pvsm"
  assert:
    - type: llm-rubric
      subtype: vision
      value: |
          1. Overall Visualization Goal: How well does the result achieve the overall goal of showing tornado flow patterns with glyphs and streamlines?

          2. Glyph Visualization: Does the result show velocity glyphs that are appropriately sized and visible?

          3. Streamline Visualization: Does the result show streamlines that follow the flow patterns effectively?

          4. Tube Rendering: Are the streamlines rendered as tubes with appropriate thickness?

# 6. Supernova Dataset
- vars:
    question: |
        Task:

        Load the supernova dataset from "supernova/data/supernova_256x256x256_float32.raw", the information about this dataset:
        Supernova (Scalar)
        Data Scalar Type: float
        Data Byte Order: little Endian
        Data Spacing: 1x1x1
        Data Extent: 256x256x256
        Data loading is very important, make sure you correctly load the dataset according to their features.

        Then visualize it and extract two isosurfaces. One of them use color red, showing areas with low density (isovalue 40 and opacity 0.4), while the other use color blue, showing areas with high density (isovalue 150 and opacity 0.8).

        Please think step by step and make sure to fulfill all the visualization goals mentioned above. Only make the two isosurfaces visible.

        Finally, save the paraview state as "supernova/results/{agent_mode}/supernova.pvsm"
  assert:
    - type: llm-rubric
      subtype: vision
      value: |
          1. Overall Visualization Goal: How well does the result achieve the overall goal of showing the supernova structure with two distinct isosurfaces representing different density regions?

          2. Does the red isosurface show low density areas (outside regions) with lower opacity?

          3. Does the blue isosurface show high density areas (inside regions) with higher opacity?

# 7. Tangaroa Dataset
- vars:
    question: |
        Task:

        Load the tangaroa dataset from "tangaroa_300x180x120_float32_scalar3.raw", the information about this dataset:
        tangaroa (Vector)
        Data Scalar Type: float
        Data Byte Order: little Endian
        Data Extent: 300x180x120
        Number of Scalar Components: 3
        Data loading is very important, make sure you correctly load the dataset according to their features.

        Apply "streamline tracer" filter, set the "Seed Type" to point cloud, turn off the "show sphere", set the center to [81.6814, 80.708, 23.5093], and radius to 29.9

        Add "Ribbon" filter to the streamline tracer results and set width to 0.3, set the Display representation to Surface.

        In pipeline browser panel, hide everything except the ribbon filter results.

        Please think step by step and make sure to fulfill all the visualization goals mentioned above.

        Finally, save the paraview state as "tangaroa/results/{agent_mode}/tangaroa.pvsm"
  assert:
    - type: llm-rubric
      subtype: vision
      value: |
          1. Overall Visualization Goal: How well does the result reveal the tangaroa flow structures using streamlines expanded into surfaces with the Ribbon filter?

          2. Streamline Seeding: Are streamlines correctly seeded from a Point Cloud centered at [81.6814, 80.708, 23.5093] with radius 29.9, and is the seed sphere hidden?

          3. Ribbon Visualization: Are the streamlines rendered with the Ribbon filter, set to width 0.3, with Display representation as Surface, effectively showing flow surfaces?

# 8. Tornado Dataset
- vars:
    question: |
        Task:

        Load the tornado dataset from "tornado/data/tornado_64x64x64_float32_scalar3.raw", the information about this dataset:
        Tornado (Vector)
        Data Scalar Type: float
        Data Byte Order: little Endian
        Data Extent: 64x64x64
        Number of Scalar Components: 3
        Data loading is very important, make sure you correctly load the dataset according to their features.

        Add a "glyph" filter under the tornado data to display velocity glyph, set an appropriate "Scale Factor" so the glyphs are visible.

        Then add a "stream tracer" filter under the tornado data to generate streamlines. Choose "Point Cloud" as "Seed Type", and do not show sphere.

        Add a "tube" filter under the stream tracer you just created to generate tubes for visualizing the streamlines. Set an appropriate radius. Make the stream tracer invisible and the tube visible. At last, render the streamlines as tubes.

        Please think step by step and make sure to fulfill all the visualization goals mentioned above.

        Finally, save the paraview state as "tornado/results/{agent_mode}/tornado.pvsm"
  assert:
    - type: llm-rubric
      subtype: vision
      value: |
          1. Overall Visualization Goal: How well does the result achieve the overall goal of showing tornado flow patterns with glyphs and streamlines?

          2. Glyph Visualization: Does the result show velocity glyphs that are appropriately sized and visible?

          3. Streamline Visualization: Does the result show streamlines that follow the flow patterns effectively?

          4. Tube Rendering: Are the streamlines rendered as tubes with appropriate thickness?

# 9. Vortex Dataset
- vars:
    question: |
        Task:

        Load the vortex dataset from "vortex/data/vortex_128x128x128_float32.raw", the information about this dataset:
        vortex (Scalar)
        Data Scalar Type: float
        Data Byte Order: little Endian
        Data Extent: 128x128x128
        Number of Scalar Components: 1

        Instructions:

        1. Load the dataset into ParaView.

        2. Leverage "contour" filter to achieve iso-surface rendering. In pipeline browser panel, hide everything except the "contour" fileter.

        3. In properties panel of "contour" filter, set isosurface value to -0.2, use Solid Color and set the color as beige.

        4. Enable Ambient occlusion by toggle the "Use Ambient Occlusion" button in the Render Passes.

        5. Add head light with light inspector, set "Coords" as Camera, "Intentsity" to 0.2, Type to "Directional".

        6. Save your work:
        Save the ParaView state as "vortex/results/{agent_mode}/vortex.pvsm".
  assert:
    - type: llm-rubric
      subtype: vision
      value: |
          1. Overall Visualization Goal: How well does the result present a clear iso-surface rendering of the vortex scalar field at value −0.2?

          2. Contour Appearance: Is the contour rendered with Solid Color set to beige and made the only visible object in the pipeline?

          3. Lighting & Shading: Are Ambient Occlusion and a directional head light (Coords = Camera, Intensity = 0.2) applied?

# 10. Foot Dataset
- vars:
    question: |
        Task:

        Load the Foot dataset from "foot/data/foot_256x256x256_uint8.raw", the information about this dataset:
        Foot
        Description: Rotational C-arm x-ray scan of a human foot. Tissue and bone are present in the dataset.
        Data Type: uint8
        Data Byte Order: little Endian
        Data Spacing: 1x1x1
        Data Extent: 256x256x256
        Data loading is very important, make sure you correctly load the dataset according to their features.

        Visualize the anatomical structures:
        1. Apply volume rendering with an X-ray transfer function that distinguishes soft tissues and bones. Bones with darker color, and soft tissue with lighter color.

        2. Analyze the visualization and answer the following questions:

        Q1: Based on the X-ray style volume rendering of the foot dataset, which of the following best describes the visibility of bony structures?
        A. Both the phalanges and metatarsals are fully visible
        B. The phalanges are fully visible, but the metatarsals are only partially visible
        C. The metatarsals are fully visible, but the phalanges are only partially visible
        D. Neither the phalanges nor the metatarsals are clearly visible

        3. Save your work:
        Save the ParaView state as "foot/results/{agent_mode}/foot.pvsm".
        Save the answers to the analysis questions in plain text as "foot/results/{agent_mode}/answers.txt".
  assert:
    - type: llm-rubric
      subtype: vision
      value: |
          1. Overall Goal: Does the visualization effectively distinguish between different tissue types in the foot dataset?

          2. X-ray Appearance: Does the visualization resemble an X-ray (monochrome or grayscale, transparent look, consistent lighting)?

    - type: llm-rubric
      subtype: text
      value: |
          1. Q1 correct answer: B. The phalanges are fully visible, but the metatarsals are only partially visible

# 11. Lobster Dataset
- vars:
    question: |
        Task:

        Load the Lobster dataset from "lobster/data/lobster_301x324x56_uint8.raw", the information about this dataset:
        Lobster
        Description: CT scan of a lobster contained in a block of resin.
        Data Type: uint8
        Data Byte Order: little Endian
        Data Spacing: 1x1x1.4
        Data Extent: 301x324x56
        Data loading is very important, make sure you correctly load the dataset according to their features.

        Visualize the scanned specimen:
        1. Create an isosurface at the specimen boundary, find a proper isovalue to show the whole structure.

        2. Use natural colors appropriate for the specimen (red-orange for lobster)

        3. Analyze the visualization and answer the following questions:

        Q1: Based on the isosurface visualization of the lobster specimen, how many walking legs are visible?
        A. 6 walking legs
        B. 7 walking legs
        C. 8 walking legs
        D. 10 walking legs

        4. Save your work:
        Save the ParaView state as "lobster/results/{agent_mode}/lobster.pvsm".
        Save the answers to the analysis questions in plain text as "lobster/results/{agent_mode}/answers.txt".
  assert:
    - type: llm-rubric
      subtype: vision
      value: |
          1. Overall Goal: Does the visualization clearly show the structure and details of the Lobster?

          2. Boundary Clearity: Are surface details and boundaries of the lobster well-defined?

          3. Correct Color: Is the color of the lobster mimic a real one? (red-orange)

    - type: llm-rubric
      subtype: text
      value: |
          1. Q1 correct answer: B. 7 walking legs

# 12. Chameleon Dataset (IsoSurface)
- vars:
    question: |
        Task:
        Load the chameleon dataset from "chameleon_isosurface/data/chameleon_isosurface_256x256x256_float32.vtk".
        Generate a visualization image of 2 isosurfaces of the Chameleon scalar field dataset with the following visualization settings:
        1) Create isosurfaces of Iso_1 with a value of 0.12 and Iso_2 with a value of 0.45
        2) Assign RGB color of [0.0, 1.0, 0.0] to Iso_1, and color of [1.0, 1.0, 1.0] to Iso_2
        3) Assign opacity of 0.1 to Iso_1, and opacity of 0.99 to Iso_2
        4) Set the lighting parameter as: 0.1 to Ambient; 0.7 to Diffuse; 0.6 to Specular
        5) Set the viewpoint parameters as: [600, 0, 0] to position; [0, 0, 0] to focal point; [0, -1, 0] to camera up direction
        6) White background
        7) Visualization image resolution is 1024x1024
        8) Save the visualization image as a png file "chameleon_isosurface/results/{agent_mode}/chameleon_isosurface.png"
        9) (Option 1) Save the paraview state as "chameleon_isosurface/results/{agent_mode}/chameleon_isosurface.pvsm" if you are using ParaView as the visualization tool
        10) (Option 2) Save the cxx code script as "chameleon_isosurface/results/{agent_mode}/chameleon_isosurface.cxx" if you are using VTK as the visualization tool
        You should only choose one of Option 1 or Option 2 to save your work. Do not save any other files, and always save the visualization image.
  assert:
    - type: llm-rubric
      subtype: vision
      value: |
          1. Overall Visualization Goal: Does the result present a good isosurface rendering compared to groundtruth?
          
          2. Is the skin of the Chameleon object of green color?
          
          3. Is the bone of the Chameleon object of white color?


# 13. Argon Bubble
# A CFD simulation of a bubble of argon gas immersed in air and being hit by a shockwave. 
# This dataset is a time-varying volume dataset created by the Center for Computational Sciences and Engineering (CCSE) at Lawrence Berkeley National Laboratory.
# The volumetric used for the SciVis benchmark is one frame of the time sequence.
- vars:
    question: |
        Task:
        Load the Argon Bubble dataset from "argon-bubble/data/argon-bubble_128x128x256_float32.vtk".
        Generate a visualization image of the Argon Bubble scalar field dataset with the following visualization settings:
        1) Create volume rendering
        2) Set the opacity transfer function as a ramp function across values of the volumetric data, assigning opacity 0 to value 0 and assigning opacity 1 to value 1.
        3) Set the color transfer function to assign a warm red color [0.71, 0.02, 0.15] to the highest value, a cool color [0.23, 0.29, 0.75] to the lowest value, and a grey color[0.87, 0.87, 0.87] to the midrange value
        4) Set the viewpoint parameters as: [0, 450, 0] to position; [0, 0, -15] to focal point; [0, 0, -1] to camera up direction
        5) Visualization image resolution is 1024x1024. White background. Shade turned off. Volume rendering ray casting sample distance is 0.1
        6) Save the visualization image as a png file "argon-bubble/results/{agent_mode}/argon-bubble.png"
        7) (Option 1) Save the paraview state as "argon-bubble/results/{agent_mode}/argon-bubble.pvsm" if you are using ParaView as the visualization tool
        8) (Option 2) Save the cxx code script as "argon-bubble/results/{agent_mode}/argon-bubble.cxx" if you are using VTK as the visualization tool
        You should only choose one of Option 1 or Option 2 to save your work. Do not save any other files, and always save the visualization image.
  assert:
    - type: llm-rubric
      subtype: vision
      value: |
          1. Does the visualization image clearly show the regions of cool, warm, and mild regions?

          2. Does the blueish region show areas with low opacity?

          3. Does the reddish region show areas with high opacity?


# 14. Richtmyer-Meshkov Instability Simulation
# Entropy field (timestep 160) of Richtmyer-Meshkov instability simulation
- vars:
    question: |
        Task:
        Load the Richtmyer dataset from "richtmyer/data/richtmyer_256x256x240_float32.vtk".
        Generate a visualization image of the Richtmyer dataset, Entropy field (timestep 160) of Richtmyer-Meshkov instability simulation, with the following visualization settings: 
        1) Create volume rendering
        2) Set the opacity transfer function as a ramp function from value 0.05 to 1 of the volumetric data, assigning opacity 0 to value less than 0.05 and assigning opacity 1 to value 1.
        3) Set the color transfer function following the 7 rainbow colors and assign a red color [1.0, 0.0, 0.0] to the highest value, a purple color [0.5, 0.0, 1.0] to the lowest value.
        4) Visualization image resolution is 1024x1024
        5) Set the viewpoint parameters as: [420, 420, -550] to position; [128, 128, 150] to focal point; [-1, -1, 1] to camera up direction
        6) Turn on the shade and set the ambient, diffuse and specular as 1.0
        7) White background. Volume rendering ray casting sample distance is 0.1
        8) Save the visualization image as a png file "richtmyer/results/{agent_mode}/richtmyer.png"
        9) (Option 1) Save the paraview state as "richtmyer/results/{agent_mode}/richtmyer.pvsm" if you are using ParaView as the visualization tool
        10) (Option 2) Save the cxx code script as "richtmyer/results/{agent_mode}/richtmyer.cxx" if you are using VTK as the visualization tool
        You should only choose one of Option 1 or Option 2 to save your work. Do not save any other files, and always save the visualization image.
  assert:
    - type: llm-rubric
      subtype: vision
      value: |
          1. Does the visualization show a clear surface with peaks and valleys?

          2. Are the peaks highlighted with the color yellow?

          3. Are the valleys highlighted with the color blue?


# 15. Rayleigh-Taylor Instability (Miranda)
# A time step of a density field in a simulation of the mixing transition in Rayleigh-Taylor instability
- vars:
    question: |
        Task:
        Load the Rayleigh-Taylor Instability dataset from "miranda/data/miranda_256x256x256_float32.vtk".
        Generate a visualization image of the Rayleigh-Taylor Instability dataset, a time step of a density field in a simulation of the mixing transition in Rayleigh-Taylor instability, with the following visualization settings:
        1) Create volume rendering
        2) Set the opacity transfer function as a ramp function from value 0 to 1 of the volumetric data, assigning opacity 0 to value 0 and assigning opacity 1 to value 1.
        3) Set the color transfer function following the 7 rainbow colors and assign a red color [1.0, 0.0, 0.0] to the highest value, a purple color [0.5, 0.0, 1.0] to the lowest value.
        4) Set the viewpoint parameters as: [650, 650, 650] to position; [128, 128, 128] to focal point; [1, 0, 0] to camera up direction
        5) Volume rendering ray casting sample distance is 0.1
        6) White background
        7) Visualization image resolution is 1024x1024
        8) Save the visualization image as a png file "miranda/results/{agent_mode}/miranda.png"
        9) (Option 1) Save the paraview state as "miranda/results/{agent_mode}/miranda.pvsm" if you are using ParaView as the visualization tool
        10) (Option 2) Save the cxx code script as "miranda/results/{agent_mode}/miranda.cxx" if you are using VTK as the visualization tool
        You should only choose one of Option 1 or Option 2 to save your work. Do not save any other files, and always save the visualization image.
  assert:
    - type: llm-rubric
      subtype: vision
      value: |
          1. Does the visualization image clearly show the regions from low to high intensity?

          2. Does the purple region show areas with low opacity?

          3. Does the red region show areas with high opacity?


# 16. Rotstrat
# Temperature field of a direct numerical simulation of rotating stratified turbulence
- vars:
    question: |
        Task:
        Load the rotstrat dataset from "rotstrat/data/rotstrat_256x256x256_float32.vtk".
        Generate a visualization image of the Rotstrat dataset, temperature field of a direct numerical simulation of rotating stratified turbulence, with the following visualization settings: 
        1) Create volume rendering
        2) Set the opacity transfer function as a step function jumping from 0 to 1 at value 0.12
        3) Set the color transfer function to assign a warm red color [0.71, 0.02, 0.15] to the highest value, a cool color [0.23, 0.29, 0.75] to the lowest value, and a grey color[0.87, 0.87, 0.87] to the midrange value
        4) Set the viewpoint parameters as: [800, 128, 128] to position; [0, 128, 128] to focal point; [0, 1, 0] to camera up direction
        5) Volume rendering ray casting sample distance is 0.1
        6) White background
        7) Visualization image resolution is 1024x1024
        8) Save the visualization image as a png file "rotstrat/results/{agent_mode}/rotstrat.png"
        9) (Option 1) Save the paraview state as "rotstrat/results/{agent_mode}/rotstrat.pvsm" if you are using ParaView as the visualization tool
        10) (Option 2) Save the cxx code script as "rotstrat/results/{agent_mode}/rotstrat.cxx" if you are using VTK as the visualization tool
        You should only choose one of Option 1 or Option 2 to save your work. Do not save any other files, and always save the visualization image.
  assert:
    - type: llm-rubric
      subtype: vision
      value: |
          1. Does the visualization image clearly show the shape of turbulence compared to ground truth?

          2. Does the blueish region show areas with low opacity?

          3. Does the reddish region show areas with high opacity?


# Vector Field Cases
# 17. MHD Turbulence Velocity Field (t=10) (mhd-turbulence_glyph)
# Isothermal magnetohydrodynamic (MHD) simulations capturing compressible turbulence phenomena relevant to astrophysical systems. 
# MHD turbulence is an essential component of the solar wind, galaxy formation, and interstellar medium (ISM) dynamics. 
# The simulations model fluid dynamics governed by conservation equations for mass, momentum, and magnetic fields, exploring MHD flows across multiple regimes—subsonic and supersonic velocities, as well as sub-Alfvénic and super-Alfvénic magnetic conditions.
# Three field types are captured: density (scalar), velocity (vector), and magnetic field (vector). Data source: The Well (Polymathic AI).
- vars:
    question: |
        Load the MHD turbulence velocity field dataset from "mhd-turbulence_glyph/data/mhd-turbulence_glyph.vti" (VTI format, 128x128x128 grid).
        Create a slice at z=64 through the volume. On this slice, place arrow glyphs oriented by the velocity vector field and scaled by velocity magnitude. 
        Color the arrows using the 'Cool to Warm' colormap mapped to velocity magnitude. 
        Use a sampling stride of 4 to avoid overcrowding. Set the glyph scale factor to 5.0. 
        Add a color bar labeled 'Velocity Magnitude'. 
        Use a dark background (RGB: 0.1, 0.1, 0.15). 
        Set the camera to a top-down view looking along the negative z-axis. Render at 1024x1024 resolution.
        Save the paraview state as "mhd-turbulence_glyph/results/{agent_mode}/mhd-turbulence_glyph.pvsm".
        Save the visualization image as "mhd-turbulence_glyph/results/{agent_mode}/mhd-turbulence_glyph.png".
        (Optional, if use python script) Save the python script as "mhd-turbulence_glyph/results/{agent_mode}/mhd-turbulence_glyph.py".
        Do not save any other files, and always save the visualization image.
  assert:
    - type: llm-rubric
      subtype: vision
      value: |
        1) Arrow glyphs oriented by velocity vector
        2) Glyphs scaled by velocity magnitude
        3) Color mapping using Cool to Warm colormap on magnitude
        4) Color bar present with label 'Velocity Magnitude'
        5) Dark background color, Top-down camera view, and Output resolution 1024x1024


# 18. Rayleigh-Taylor Instability Velocity Field (t=50) (rti-velocity_glyph)
# Rayleigh-Taylor instability simulations examining how varying spectral characteristics and random phase components influence the development of turbulent mixing. 
# The simulations investigate three key physical aspects: the impact of coherence on randomized initial conditions, how initial energy spectrum shapes affect resulting flow structures, and the transition from Boussinesq to non-Boussinesq regimes where mixing becomes asymmetric.
# The dataset captures the self-similar growth of the turbulent mixing zone, enabling validation of the dimensionless mixing parameter and observation of the characteristic energy cascade. 
# Data source: The Well (Polymathic AI)
- vars:
    question: |
        Load the Rayleigh-Taylor instability velocity field dataset from "rti-velocity_glyph/data/rti-velocity_glyph.vti" (VTI format, 128x128x128 grid). 
        Create a slice at y=64 through the volume. 
        Place arrow glyphs on the slice, oriented by the velocity vector. Use uniform arrow size (no magnitude scaling, scale factor 3.0).
        Color the arrows by velocity magnitude using the 'Viridis (matplotlib)' colormap. Use a sampling stride of 3. 
        Add a color bar labeled 'Velocity Magnitude'.
        Use a black background. 
        Set the camera to view along the negative y-axis. Render at 1024x1024.
        Save the paraview state as "rti-velocity_glyph/results/{agent_mode}/rti-velocity_glyph.pvsm".
        Save the visualization image as "rti-velocity_glyph/results/{agent_mode}/rti-velocity_glyph.png".
        (Optional, if use python script) Save the python script as "rti-velocity_glyph/results/{agent_mode}/rti-velocity_glyph.py".
        Do not save any other files, and always save the visualization image.
  assert:
    - type: llm-rubric
      subtype: vision
      value: |
        1) Arrow glyphs oriented by velocity vector
        2) Uniform arrow size (no magnitude scaling)
        3) Color by velocity magnitude with Viridis colormap 
        4) Color bar present labeled 'Velocity Magnitude'
        5) Black background, Camera along negative y-axis, and Output resolution 1024x1024


# 19. MHD Magnetic Field (t=10) (mhd-magfield_glyph)
# Isothermal magnetohydrodynamic (MHD) simulations capturing compressible turbulence phenomena relevant to astrophysical systems.
# MHD turbulence is an essential component of the solar wind, galaxy formation, and interstellar medium (ISM) dynamics. 
# The simulations model fluid dynamics governed by conservation equations for mass, momentum, and magnetic fields, exploring MHD flows across multiple regimes—subsonic and supersonic velocities, as well as sub-Alfvénic and super-Alfvénic magnetic conditions. 
# Three field types are captured: density (scalar), velocity (vector), and magnetic field (vector). 
# Data source: The Well (Polymathic AI)
- vars:
    question: |
        Load the MHD magnetic field dataset from "mhd-magfield_glyph/data/mhd-magfield_glyph.vti" (VTI format, 128x128x128 grid with components bx, by, bz). 
        Create a slice at x=64 through the volume. 
        Place arrow glyphs oriented by the magnetic field vector and scaled by field magnitude (scale factor 5.0). 
        Color the arrows using the 'Plasma (matplotlib)' colormap mapped to magnitude. Use stride of 4. 
        Add a color bar labeled 'Magnetic Field Magnitude'. 
        Use a dark navy background (RGB: 0.0, 0.0, 0.15). Set camera to view along the negative x-axis. Render at 1024x1024.
        Save the paraview state as "mhd-magfield_glyph/results/{agent_mode}/mhd-magfield_glyph.pvsm".
        Save the visualization image as "mhd-magfield_glyph/results/{agent_mode}/mhd-magfield_glyph.png".
        (Optional, if use python script) Save the python script as "mhd-magfield_glyph/results/{agent_mode}/mhd-magfield_glyph.py".
        Do not save any other files, and always save the visualization image.
  assert:
    - type: llm-rubric
      subtype: vision
      value: |
        1) Arrow glyphs oriented by magnetic field vector
        2) Glyphs scaled by field magnitude
        3) Plasma colormap applied to magnitude
        4) Color bar present labeled 'Magnetic Field Magnitude
        5) Dark navy background, Camera along negative x-axis, Output resolution 1024x1024


# 20. MHD Turbulence Velocity Field (t=30) (mhd-turbulence_streamline)
# Isothermal magnetohydrodynamic (MHD) simulations capturing compressible turbulence phenomena relevant to astrophysical systems.
# MHD turbulence is an essential component of the solar wind, galaxy formation, and interstellar medium (ISM) dynamics.
# The simulations model fluid dynamics governed by conservation equations for mass, momentum, and magnetic fields, exploring MHD flows across multiple regimes—subsonic and supersonic velocities, as well as sub-Alfvénic and super-Alfvénic magnetic conditions.
# Three field types are captured: density (scalar), velocity (vector), and magnetic field (vector). 
# Data source: The Well (Polymathic AI)
- vars:
    question: |
        Load the MHD turbulence velocity field dataset "mhd-turbulence_streamline/data/mhd-turbulence_streamline.vti" (VTI format, 128x128x128 grid). 
        Generate 3D streamlines seeded from a line source along the z-axis at x=64, y=64 (from z=0 to z=127), with 50 seed points. 
        Color the streamlines by velocity magnitude using the 'Turbo' colormap. Set streamline tube radius to 0.3 using the Tube filter. 
        Add a color bar labeled 'Velocity Magnitude'. Use a dark background (RGB: 0.05, 0.05, 0.1). Set an isometric camera view. Render at 1024x1024.
        Save the paraview state as "mhd-turbulence_streamline/results/{agent_mode}/mhd-turbulence_streamline.pvsm".
        Save the visualization image as "mhd-turbulence_streamline/results/{agent_mode}/mhd-turbulence_streamline.png".
        (Optional, if use python script) Save the python script as "mhd-turbulence_streamline/results/{agent_mode}/mhd-turbulence_streamline.py".
        Do not save any other files, and always save the visualization image.
  assert:
    - type: llm-rubric
      subtype: vision
      value: |
       1) Streamlines generated from line seed along z-axis, with similar pattern compared to groundtruth
       2) Streamlines rendered as tubes
       3) Color by velocity magnitude with Turbo colormap
       4) Color bar labeled 'Velocity Magnitude'
       5) Dark background, Isometric camera view, Output resolution 1024x1024


# 21. Rayleigh-Taylor Instability Velocity Field (t=70) (rti-velocity_streamline)
# Rayleigh-Taylor instability simulations examining how varying spectral characteristics and random phase components influence the development of turbulent mixing. 
# The simulations investigate three key physical aspects: the impact of coherence on randomized initial conditions, how initial energy spectrum shapes affect resulting flow structures, and the transition from Boussinesq to non-Boussinesq regimes where mixing becomes asymmetric.
# The dataset captures the self-similar growth of the turbulent mixing zone, enabling validation of the dimensionless mixing parameter and observation of the characteristic energy cascade. 
# Data source: The Well (Polymathic AI)
- vars:
    question: |
        Load the Rayleigh-Taylor instability velocity field dataset from "rti-velocity_streamline/data/rti-velocity_streamline.vti" (VTI format, 128x128x128 grid). 
        Generate streamlines seeded from a plane at y=64 (using a Point Cloud seed with 200 points distributed on the xz-plane at y=64). 
        Color the streamlines by the vz component using a 'Cool to Warm (Extended)' diverging colormap. Render streamlines as tubes with radius 0.4. 
        Add a color bar labeled 'Vz Component'. 
        Dark background (RGB: 0.02, 0.02, 0.05). Use an isometric camera view. Render at 1024x1024.
        Save the paraview state as "rti-velocity_streamline/results/{agent_mode}/rti-velocity_streamline.pvsm".
        Save the visualization image as "rti-velocity_streamline/results/{agent_mode}/rti-velocity_streamline.png".
        (Optional, if use python script) Save the python script as "rti-velocity_streamline/results/{agent_mode}/rti-velocity_streamline.py".
        Do not save any other files, and always save the visualization image.
  assert:
    - type: llm-rubric
      subtype: vision
      value: |
        1) Streamlines seeded from y=64 plane region, with similar pattern compared to groundtruth
        2) Streamlines rendered as tubes
        3) Color by vz with Cool to Warm diverging colormap
        4) Color bar labeled 'Vz Component'
        5) Dark background, Isometric camera view, Output resolution 1024x1024


# 22. Turbulent Radiative Layer Velocity Field (tcool=0.10, t=50) (trl-velocity_streamline)
# Turbulent Radiative Layer simulations of astrophysical mixing processes where cold, dense gas interfaces with hot, dilute gas moving at subsonic velocities. 
# The cold dense gas on the bottom and hot dilute gas on the top becomes unstable to the Kelvin-Helmholtz instability. 
# When turbulence causes mixing, intermediate-temperature gas forms and rapidly cools, creating a net mass transfer from the hot phase to the cold phase—a process relevant to interstellar and circumgalactic environments. 
# Generated using Athena++. Data source: The Well (Polymathic AI)
- vars:
    question: |
        Load the turbulent radiative layer velocity field dataset from "trl-velocity_streamline/data/trl-velocity_streamline.vti" (VTI format, 256x128x128 grid). 
        Generate streamlines seeded from a line along the x-axis at y=64, z=64 (from x=0 to x=255), with 100 seed points. 
        Color streamlines by velocity magnitude using the 'Inferno (matplotlib)' colormap. Render as tubes with radius 0.5. 
        Add a color bar labeled 'Velocity Magnitude'. 
        Dark background (RGB: 0.0, 0.0, 0.0). Set an isometric camera view. Render at 1024x1024."
        Save the paraview state as "trl-velocity_streamline/results/{agent_mode}/trl-velocity_streamline.pvsm".
        Save the visualization image as "trl-velocity_streamline/results/{agent_mode}/trl-velocity_streamline.png".
        (Optional, if use python script) Save the python script as "trl-velocity_streamline/results/{agent_mode}/trl-velocity_streamline.py".
        Do not save any other files, and always save the visualization image.
  assert:
    - type: llm-rubric
      subtype: vision
      value: |
        1) Streamlines seeded along x-axis line, with similar pattern compared to groundtruth
        2) Streamlines rendered as tubes 
        3) Color by magnitude with Inferno colormap
        4) Color bar labeled 'Velocity Magnitude'
        5) Black background, Isometric camera view, Output resolution 1024x1024


# 23. MHD Magnetic Field (t=40) (mhd-magfield_volvis)
# Isothermal magnetohydrodynamic (MHD) simulations capturing compressible turbulence phenomena relevant to astrophysical systems.
# MHD turbulence is an essential component of the solar wind, galaxy formation, and interstellar medium (ISM) dynamics. 
# The simulations model fluid dynamics governed by conservation equations for mass, momentum, and magnetic fields, exploring MHD flows across multiple regimes—subsonic and supersonic velocities, as well as sub-Alfvénic and super-Alfvénic magnetic conditions. 
# Three field types are captured: density (scalar), velocity (vector), and magnetic field (vector). 
# Data source: The Well (Polymathic AI)
- vars:
    question: |
        Load the MHD magnetic field dataset from "mhd-magfield_volvis/data/mhd-magfield_volvis.vti" (VTI format, 128x128x128 grid). 
        Compute the magnetic field magnitude from components (bx, by, bz). Perform volume rendering of the magnitude field. 
        Use the 'Cool to Warm' colormap with an opacity transfer function that makes low-magnitude regions transparent and high-magnitude regions opaque. 
        Add a color bar labeled 'B Magnitude'. 
        Use a dark background (RGB: 0.0, 0.0, 0.05). Set an isometric camera view. Render at 1024x1024.
        Save the paraview state as "mhd-magfield_volvis/results/{agent_mode}/mhd-magfield_volvis.pvsm".
        Save the visualization image as "mhd-magfield_volvis/results/{agent_mode}/mhd-magfield_volvis.png".
        (Optional, if use python script) Save the python script as "mhd-magfield_volvis/results/{agent_mode}/mhd-magfield_volvis.py".
        Do not save any other files, and always save the visualization image.        
  assert:
    - type: llm-rubric
      subtype: vision
      value: |
        1) Volume rendering representation applied based on magnitude field, generally similar to groundtruth
        2) Cool to Warm colormap
        3) Opacity transfer function correctly set: low=transparent, high=opaque
        4) Color bar labeled 'B Magnitude' 
        5) Dark background, Isometric camera, Output resolution 1024x1024


# 24. Turbulence Gravity Cooling Velocity (temp=1000K, dens=4.45, metal=0.1Z, t=20) (tgc-velocity_volvis)
# Turbulence-gravity-cooling simulations modeling turbulent fluid with gravity representing the interstellar medium in galaxies. 
# These simulations capture the formation of dense filaments that seed star formation, with filament frequency and timescales varying based on cooling strength.
# The dataset encompasses three density regimes with systematically varied initial temperatures and metallicity levels representing different cosmic epochs, 
# governed by coupled equations for pressure, density, momentum, and internal energy incorporating gravitational forces, viscosity, and radiative heating/cooling. 
# Data source: The Well (Polymathic AI).
- vars:
    question: |
        Load the turbulence-gravity-cooling velocity field dataset from "tgc-velocity_volvis/data/tgc-velocity_volvis.vti" (VTI format, 64x64x64 grid). 
        Perform volume rendering of velocity magnitude. Use the 'Viridis (matplotlib)' colormap. 
        Set opacity transfer function to gradually increase from 0 at minimum to 0.8 at maximum. 
        Add a color bar labeled 'Velocity Magnitude'. 
        Dark gray background (RGB: 0.1, 0.1, 0.1). Isometric camera view. Render at 1024x1024.
        Save the paraview state as "tgc-velocity_volvis/results/{agent_mode}/tgc-velocity_volvis.pvsm".
        Save the visualization image as "tgc-velocity_volvis/results/{agent_mode}/tgc-velocity_volvis.png".
        (Optional, if use python script) Save the python script as "tgc-velocity_volvis/results/{agent_mode}/tgc-velocity_volvis.py".
        Do not save any other files, and always save the visualization image.
  assert:
    - type: llm-rubric
      subtype: vision
      value: |
        1) Volume rendering applied, generally similar to groundtruth
        2) Viridis colormap
        3) Gradual opacity transfer function
        4) Color bar labeled 'Velocity Magnitude'
        5) Dark gray background, Isometric camera, Output resolution 1024x1024


# 25. Rayleigh-Taylor Instability Velocity Field (t=40) (rti-velocity_divergence)
# Rayleigh-Taylor instability simulations examining how varying spectral characteristics and random phase components influence the development of turbulent mixing. 
# The simulations investigate three key physical aspects: the impact of coherence on randomized initial conditions, how initial energy spectrum shapes affect resulting flow structures, and the transition from Boussinesq to non-Boussinesq regimes where mixing becomes asymmetric.
# The dataset captures the self-similar growth of the turbulent mixing zone, enabling validation of the dimensionless mixing parameter and observation of the characteristic energy cascade. 
# Data source: The Well (Polymathic AI)
- vars:
    question: |
        Load the Rayleigh-Taylor instability velocity field from "rti-velocity_divergence/data/rti-velocity_divergence.vti" (VTI format, 128x128x128). 
        Compute the divergence of the velocity field using the Gradient filter with 'Compute Divergence' enabled. 
        Extract a slice at z=64 and color it by divergence using the 'Cool to Warm' diverging colormap (centered at 0). 
        Add a color bar labeled 'Velocity Divergence'. 
        White background. Top-down camera view along negative z-axis. Render at 1024x1024.
        Save the paraview state as "rti-velocity_divergence/results/{agent_mode}/rti-velocity_divergence.pvsm".
        Save the visualization image as "rti-velocity_divergence/results/{agent_mode}/rti-velocity_divergence.png".
        (Optional, if use python script) Save the python script as "rti-velocity_divergence/results/{agent_mode}/rti-velocity_divergence.py".
        Do not save any other files, and always save the visualization image
  assert:
    - type: llm-rubric
      subtype: vision
      value: |
        1) Divergence computation from velocity field, with similar pattern compared to groundtruth
        2) Cool to Warm diverging colormap centered at 0
        3) Color bar labeled 'Velocity Divergence'
        4) White background, Top-down camera along negative z, Output resolution 1024x1024


# 26. Turbulent Radiative Layer Velocity Field (tcool=1.00, t=30) (trl-velocity_isosurface)
# Turbulent Radiative Layer simulations of astrophysical mixing processes where cold, dense gas interfaces with hot, dilute gas moving at subsonic velocities. 
# The cold dense gas on the bottom and hot dilute gas on the top becomes unstable to the Kelvin-Helmholtz instability. 
# When turbulence causes mixing, intermediate-temperature gas forms and rapidly cools, creating a net mass transfer from the hot phase to the cold phase—a process relevant to interstellar and circumgalactic environments. 
# Generated using Athena++. Data source: The Well (Polymathic AI)
- vars:
    question: |
        Load the turbulent radiative layer velocity field dataset from "trl-velocity_isosurface/data/trl-velocity_isosurface.vti" (VTI format, 256x128x128). 
        Extract an isosurface of velocity magnitude at the value 0.8. Color the isosurface by the vx component using the 'Cool to Warm' colormap. 
        Add a color bar labeled 'Vx Component'. 
        Dark background (RGB: 0.05, 0.05, 0.1). Isometric camera view. Render at 1024x1024.
        Save the paraview state as "trl-velocity_isosurface/results/{agent_mode}/trl-velocity_isosurface.pvsm".
        Save the visualization image as "trl-velocity_isosurface/results/{agent_mode}/trl-velocity_isosurface.png".
        (Optional, if use python script) Save the python script as "trl-velocity_isosurface/results/{agent_mode}/trl-velocity_isosurface.py".
        Do not save any other files, and always save the visualization image.
  assert:
    - type: llm-rubric
      subtype: vision
      value: |
        1) Isosurface extraction at magnitude=0.8, with similar pattern compared to groundtruth
        2) Isosurface colored by vx component
        3) Cool to Warm colormap
        4) Color bar labeled 'Vx Component'
        5) Dark background, Isometric camera, Output resolution 1024x1024


# 27. Supernova Explosion Velocity Field (t=30) (supernova-velocity_streamline)
# Supernova explosion simulations capturing the physical dynamics of a stellar explosion propagating through a dense interstellar medium.
# The simulations inject thermal energy of 10^51 ergs at the center of a computational domain, generating a blastwave that sweeps through ambient gas and creates supernova feedback structures—an explosion inside a compression of a monatomic ideal gas modeling conditions in the Milky Way Galaxy interstellar medium. 
# The simulations employ sophisticated physics including radiative cooling and heating. 
# Data source: The Well (Polymathic AI).
- vars:
    question: |
        Load the supernova explosion velocity field dataset from "supernova-velocity_streamline/data/supernova-velocity_streamline.vti" (VTI format, 128x128x128 grid). 
        Generate streamlines seeded from a line source along the diagonal from (20,20,20) to (108,108,108) with 80 seed points. 
        Color streamlines by velocity magnitude using the 'Magma (matplotlib)' colormap. 
        Render as tubes with radius 0.4. 
        Add a color bar labeled 'Velocity Magnitude'. 
        Dark background (RGB: 0.02, 0.0, 0.05). Isometric camera view. Render at 1024x1024.
        Save the paraview state as "supernova-velocity_streamline/results/{agent_mode}/supernova-velocity_streamline.pvsm".
        Save the visualization image as "supernova-velocity_streamline/results/{agent_mode}/supernova-velocity_streamline.png".
        (Optional, if use python script) Save the python script as "supernova-velocity_streamline/results/{agent_mode}/supernova-velocity_streamline.py".
        Do not save any other files, and always save the visualization image.
  assert:
    - type: llm-rubric
      subtype: vision
      value: |
        1) Streamlines seeded from diagonal line, with similar pattern compared to groundtruth
        2) Streamlines as tubes
        3) Color by magnitude with Magma colormap
        4) Color bar labeled 'Velocity Magnitude'
        5) Dark background, Isometric camera, Output resolution 1024x1024


# 28. MHD Turbulence Velocity Field (t=50) (mhd-turbulence_vorticity)
# Isothermal magnetohydrodynamic (MHD) simulations capturing compressible turbulence phenomena relevant to astrophysical systems.
# MHD turbulence is an essential component of the solar wind, galaxy formation, and interstellar medium (ISM) dynamics.
# The simulations model fluid dynamics governed by conservation equations for mass, momentum, and magnetic fields, exploring MHD flows across multiple regimes—subsonic and supersonic velocities, as well as sub-Alfvénic and super-Alfvénic magnetic conditions.
# Three field types are captured: density (scalar), velocity (vector), and magnetic field (vector). 
# Data source: The Well (Polymathic AI)
- vars:
    question: |
        Load the MHD turbulence velocity field dataset "mhd-turbulence_vorticity/data/mhd-turbulence_vorticity.vti" (VTI format, 128x128x128 grid).
        Compute the vorticity field (curl of velocity) using the Gradient filter with 'Compute Vorticity' enabled.
        Then compute vorticity magnitude. Perform volume rendering of vorticity magnitude using the 'Plasma (matplotlib)' colormap. 
        Set opacity to highlight high-vorticity regions. 
        Add a color bar labeled 'Vorticity Magnitude'. 
        Black background. Isometric camera. Render at 1024x1024.
        Save the paraview state as "mhd-turbulence_vorticity/results/{agent_mode}/mhd-turbulence_vorticity.pvsm".
        Save the visualization image as "mhd-turbulence_vorticity/results/{agent_mode}/mhd-turbulence_vorticity.png".
        (Optional, if use python script) Save the python script as "mhd-turbulence_vorticity/results/{agent_mode}/mhd-turbulence_vorticity.py".
        Do not save any other files, and always save the visualization image.
  assert:
    - type: llm-rubric
      subtype: vision
      value: |
       1) Vorticity computation (curl of velocity), similar pattern compared to groundtruth
       2) Volume rendering of vorticity magnitude
       3) Plasma colormap
       4) Opacity highlights high-vorticity regions
       5) Color bar labeled 'Vorticity Magnitude'
       6) Black background, Isometric camera, Output resolution 1024x1024


# 29. Supernova Explosion Velocity Field (t=40) (supernova-velocity_isosurface)
# Supernova explosion simulations capturing the physical dynamics of a stellar explosion propagating through a dense interstellar medium.
# The simulations inject thermal energy of 10^51 ergs at the center of a computational domain, generating a blastwave that sweeps through ambient gas and creates supernova feedback structures—an explosion inside a compression of a monatomic ideal gas modeling conditions in the Milky Way Galaxy interstellar medium. 
# The simulations employ sophisticated physics including radiative cooling and heating. 
# Data source: The Well (Polymathic AI).
- vars:
    question: |
        Load the supernova explosion velocity field from "supernova-velocity_isosurface/data/supernova-velocity_isosurface.vti" (VTI format, 128x128x128).
        Extract an isosurface of velocity magnitude at threshold 0.7. Color the isosurface by the vz component using 'Blue to Red Rainbow' colormap. 
        Add a color bar labeled 'Vz Component'. 
        Dark background (RGB: 0.0, 0.0, 0.0). Isometric camera view. Render at 1024x1024.
        Save the paraview state as "supernova-velocity_isosurface/results/{agent_mode}/supernova-velocity_isosurface.pvsm".
        Save the visualization image as "supernova-velocity_isosurface/results/{agent_mode}/supernova-velocity_isosurface.png".
        (Optional, if use python script) Save the python script as "supernova-velocity_isosurface/results/{agent_mode}/supernova-velocity_isosurface.py".
        Do not save any other files, and always save the visualization image.
  assert:
    - type: llm-rubric
      subtype: vision
      value: |
        1) Isosurface at magnitude=0.7, similar pattern compared to groundtruth
        2) Colored by vz component
        3) Blue to Red Rainbow colormap
        4) Color bar labeled 'Vz Component'
        5) Black background, Isometric camera, Output resolution 1024x1024


# 30. MHD Magnetic Field (t=60) (mhd-magfield_isosurface)
# Isothermal magnetohydrodynamic (MHD) simulations capturing compressible turbulence phenomena relevant to astrophysical systems.
# MHD turbulence is an essential component of the solar wind, galaxy formation, and interstellar medium (ISM) dynamics. 
# The simulations model fluid dynamics governed by conservation equations for mass, momentum, and magnetic fields, exploring MHD flows across multiple regimes—subsonic and supersonic velocities, as well as sub-Alfvénic and super-Alfvénic magnetic conditions. 
# Three field types are captured: density (scalar), velocity (vector), and magnetic field (vector). 
# Data source: The Well (Polymathic AI)
- vars:
    question: |
        Load the MHD magnetic field dataset from "mhd-magfield_isosurface/data/mhd-magfield_isosurface.vti" (VTI format, 128x128x128). 
        Extract an isosurface of magnetic field magnitude at threshold 0.8. Color the isosurface by the bx component using 'Turbo' colormap. 
        Add a color bar labeled 'Bx Component'. 
        Dark navy background (RGB: 0.0, 0.0, 0.1). Isometric camera view. Render at 1024x1024.  
        Save the paraview state as "mhd-magfield_isosurface/results/{agent_mode}/mhd-magfield_isosurface.pvsm".
        Save the visualization image as "mhd-magfield_isosurface/results/{agent_mode}/mhd-magfield_isosurface.png".
        (Optional, if use python script) Save the python script as "mhd-magfield_isosurface/results/{agent_mode}/mhd-magfield_isosurface.py".
        Do not save any other files, and always save the visualization image.    
  assert:
    - type: llm-rubric
      subtype: vision
      value: |
        1) Isosurface at magnitude=0.8, similar pattern compared to groundtruth
        2) Colored by bx component
        3) Turbo colormap
        4) Color bar labeled 'Bx Component'
        5) Dark navy background, Isometric camera, Output resolution 1024x1024


# 31. Turbulence Gravity Cooling Velocity (temp=100K, dens=0.445, metal=Z, t=10) (tgc-velocity_contour)
# Turbulence-gravity-cooling simulations modeling turbulent fluid with gravity representing the interstellar medium in galaxies. 
# These simulations capture the formation of dense filaments that seed star formation, with filament frequency and timescales varying based on cooling strength.
# The dataset encompasses three density regimes with systematically varied initial temperatures and metallicity levels representing different cosmic epochs, 
# governed by coupled equations for pressure, density, momentum, and internal energy incorporating gravitational forces, viscosity, and radiative heating/cooling. 
# Data source: The Well (Polymathic AI).
- vars:
    question: |
        Load the turbulence-gravity-cooling velocity field dataset from "tgc-velocity_contour/data/tgc-velocity_contour.vti" (VTI format, 64x64x64). 
        Extract a slice at z=32 and color it by velocity magnitude using 'Viridis (matplotlib)' colormap. 
        Also add contour lines of velocity magnitude on the same slice at values [0.3, 0.6, 0.9, 1.2] using the Contour filter on the slice output. 
        Display contour lines in white. Add a color bar labeled 'Velocity Magnitude'. 
        Light gray background (RGB: 0.9, 0.9, 0.9). Top-down camera. Render at 1024x1024.
        Save the paraview state as "tgc-velocity_contour/results/{agent_mode}/tgc-velocity_contour.pvsm".
        Save the visualization image as "tgc-velocity_contour/results/{agent_mode}/tgc-velocity_contour.png".
        (Optional, if use python script) Save the python script as "tgc-velocity_contour/results/{agent_mode}/tgc-velocity_contour.py".
        Do not save any other files, and always save the visualization image.
  assert:
    - type: llm-rubric
      subtype: vision
      value: |
        1) Slice at z=32 colored by magnitude, similar pattern compared to groundtruth
        2) Viridis colormap on slice
        3) Contour lines at specified values, similar pattern compared to groundtruth
        4) White contour lines
        5) Color bar labeled 'Velocity Magnitude'
        6) Light gray background, Top-down camera, Output resolution 1024x1024


# 32. Rayleigh-Taylor Instability Velocity Field (t=80) (rti-velocity_slices)
# Rayleigh-Taylor instability simulations examining how varying spectral characteristics and random phase components influence the development of turbulent mixing. 
# The simulations investigate three key physical aspects: the impact of coherence on randomized initial conditions, how initial energy spectrum shapes affect resulting flow structures, and the transition from Boussinesq to non-Boussinesq regimes where mixing becomes asymmetric.
# The dataset captures the self-similar growth of the turbulent mixing zone, enabling validation of the dimensionless mixing parameter and observation of the characteristic energy cascade. 
# Data source: The Well (Polymathic AI)
- vars:
    question: |
        Load the Rayleigh-Taylor instability velocity field from "rti-velocity_slices/data/rti-velocity_slices.vti" (VTI format, 128x128x128). 
        Create three orthogonal slices: at x=64 (YZ-plane), y=64 (XZ-plane), and z=64 (XY-plane). 
        Color all three slices by velocity magnitude using the 'Turbo' colormap. 
        Add a color bar labeled 'Velocity Magnitude'. 
        Dark background (RGB: 0.05, 0.05, 0.05). Set an isometric camera view that shows all three slices. Render at 1024x1024.
        Save the paraview state as "rti-velocity_slices/results/{agent_mode}/rti-velocity_slices.pvsm".
        Save the visualization image as "rti-velocity_slices/results/{agent_mode}/rti-velocity_slices.png".
        (Optional, if use python script) Save the python script as "rti-velocity_slices/results/{agent_mode}/rti-velocity_slices.py".
        Do not save any other files, and always save the visualization image
  assert:
    - type: llm-rubric
      subtype: vision
      value: |
        1) Three orthogonal slices at x=64, y=64, z=64, similar pattern compared to groundtruth
        2) All slices colored by velocity magnitude
        3) Turbo colormap
        4) Color bar labeled 'Velocity Magnitude'
        5) Dark background, Isometric camera showing all three slices, Output resolution 1024x1024