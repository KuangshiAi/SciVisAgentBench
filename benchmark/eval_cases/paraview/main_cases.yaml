# Comprehensive Test Cases for SciVisAgentBench Main Tasks
# This test evaluates the ability to complete specific visualization tasks
# with detailed requirements and evaluation criteria

# 1. Bonsai Dataset
- vars:
    question: |
        Task:

        Load the bonsai dataset from "bonsai/data/bonsai_256x256x256_uint8.raw", the information about this dataset:
        Bonsai (Scalar)
        Data Scalar Type: unsigned char
        Data Byte Order: little Endian
        Data Spacing: 1x1x1
        Data Extent: 256x256x256

        Then visualize it with volume rendering, modify the transfer function and reach the visualization goal as: "A potted tree with brown pot silver branch and golden leaves."

        Please think step by step and make sure to fulfill all the visualization goals mentioned above.

        Finally, save the paraview state as "bonsai/results/{agent_mode}/bonsai.pvsm"
  assert:
    - type: llm-rubric
      subtype: vision
      value: |
          1. Brown Pot Visualization: Does the result show the pot portion in brown color?

          2. Silver Branch Visualization: Does the result show the branch/trunk portion in silver color?

          3. Golden Leaves Visualization: Does the result show the leaves portion in golden color?

# 2. Carp Dataset
- vars:
    question: |
        Task:

        Load the carp dataset from "carp/data/carp_256x256x512_uint16.raw", the information about this dataset:
        Carp (Scalar)
        Data Scalar Type: unsigned short
        Data Byte Order: little Endian
        Data Spacing: 0.78125x0.390625x1
        Data Extent: 256x256x512

        Instructions:

        1. Load the dataset into ParaView.

        2. Apply volume rendering to visualize the carp skeleton.

        3. Adjust the transfer function to highlight only the bony structures in an X-ray style (suppressing soft tissue).

        4. Optimize the viewpoint to display the full skeleton, ensuring the head, spine, and fins are all clearly visible in a single frame.

        5. Analyze the visualization and answer the following questions:

        Q1: Which of the following options correctly describes the fins visible in the carp skeleton visualization?
        A. 5 fins: 1 dorsal, 2 pectoral, 2 pelvic
        B. 6 fins: 1 dorsal, 2 pectoral, 2 pelvic, 1 caudal
        C. 7 fins: 1 dorsal, 2 pectoral, 2 pelvic, 1 anal, 1 caudal
        D. 8 fins: 2 dorsal, 2 pectoral, 2 pelvic, 1 anal, 1 caudal

        Q2: Based on the visualization, what is the approximate ratio of skull length to total body length?
        A. ~15%
        B. ~22%
        C. ~30%
        D. ~40%

        6. Save your work:
        Save the ParaView state as "carp/results/{agent_mode}/carp.pvsm".
        Save the answers to the analysis questions in plain text as "carp/results/{agent_mode}/answers.txt".
  assert:
    - type: llm-rubric
      subtype: vision
      value: |
          1. Bone Isolation: Are the bones clearly visible while soft tissue and background are suppressed? Thin fin rays should be distinguishable without major loss.

          2. Viewpoint Selection: Does the chosen viewpoint display the entire carp skeleton (head, spine, ribs, fins, tail) without critical occlusion?

          3. X-ray Appearance: Does the visualization resemble an X-ray (monochrome or grayscale, transparent look, consistent lighting)?

          4. Correct Data Setup: Was the dataset loaded with proper spacing (0.78125x0.390625x1.0)? The carp skeleton should appear in its correct proportions without distortion (i.e., the fish shape looks anatomically normal).
    - type: llm-rubric
      subtype: text
      value: |
          1. Q1 correct answer: C. 7 fins: 1 dorsal, 2 pectoral, 2 pelvic, 1 anal, 1 caudal

          2. Q2 correct answer: B. ~22%

# 3. Chameleon Dataset (VolVis)
- vars:
    question: |
        Task:

        Load the chameleon dataset from "chameleon_volvis/data/chameleon_volvis_256x256x270_float32.raw", the information about this dataset:
        chameleon (Scalar)
        Data Scalar Type: float
        Data Byte Order: little Endian
        Data Extent: 256x256x270
        Number of Scalar Components: 1
        Data loading is very important, make sure you correctly load the dataset according to their features.

        Apply the volume rendering to visualize the chameleon dataset

        Adjust the transfer function to highlight the bony structures and skin in an X-ray style.

        Adjust the camera position and focus on the head part of the chameleon

        Please think step by step and make sure to fulfill all the visualization goals mentioned above.

        Finally, save the paraview state as "chameleon_volvis/results/{agent_mode}/chameleon_volvis.pvsm"
  assert:
    - type: llm-rubric
      subtype: vision
      value: |
          1. Overall Visualization Goal: Does the result present a clean, X-ray–style volume rendering where the chameleon's bony structures are clearly emphasized and soft tissue is faint but discernible?

          2. Data Loading Correctness: Is the RAW volume loaded with the specified metadata (float32, little-endian, 256×256×270, 1 component) so that the histogram looks reasonable and the anatomy is not flipped or distorted?

          3. Transfer Function Quality: Does the grayscale transfer function make low-intensity tissue mostly transparent while assigning higher opacity to bones/skin ridges, yielding good depth cues without over-saturation or banding?

          4. Camera & Framing: Is the camera positioned and zoomed to focus on the chameleon's head, keeping it sharply framed (no clipping), with a stable viewpoint that highlights key anatomical details?

# 4. Engine Dataset
- vars:
    question: |
        Task:

        Load the vortex dataset from "engine/data/engine_256x256x128_uint8.raw", the information about this dataset:
        engine (Scalar)
        Data Scalar Type: float
        Data Byte Order: little Endian
        Data Extent: 256x256x128
        Number of Scalar Components: 1

        Instructions:

        1. Load the dataset into ParaView.

        2. Apply the volume rendering to visualize the engine dataset

        3. Adjust the transfer function, let the outer part more transparent and the inner part more solid. Use light blue for the outer part and orange for the inner part.

        4. Save your work:
        Save the ParaView state as "engine/results/{agent_mode}/engine.pvsm".
  assert:
    - type: llm-rubric
      subtype: vision
      value: |
          1. Overall Visualization Goal: How well does the result use volume rendering to clearly present the internal and external structures of the engine dataset?

          2. Structural Clarity: Does the visualization emphasize depth so that the outer layers do not obscure the inner structures?

          3. Transfer Function Transparency: Is the outer region rendered with higher transparency and the inner region more solid, achieving a clear layering effect?

          4. Transfer Function Color Mapping: Are colors correctly assigned so that the outer part is light blue and the inner part is orange, enhancing structural contrast?

# 5. Solar Plume Dataset
- vars:
    question: |
        Task:

        Load the tornado dataset from "solar-plume/data/solar-plume_126x126x512_float32_scalar3.raw", the information about this dataset:
        solar-plume (Vector)
        Data Scalar Type: float
        Data Byte Order: little Endian
        Data Extent: 126x126x512
        Number of Scalar Components: 3
        Data loading is very important, make sure you correctly load the dataset according to their features.

        Add a "stream tracer" filter under the tornado data to display streamline, set the "Seed type" to "Point Cloud" and set the center of point cloud to 3D position [50, 50, 320] with a radius 30, then hide the point cloud sphere.

        Add a "tube" filter under the "stream tracer" filter to enhance the streamline visualization. Set the radius to 0.5. In the pipeline browser panel, hide everything except the "tube" filter. 


        Please think step by step and make sure to fulfill all the visualization goals mentioned above.

        Finally, save the paraview state as "solar-plume/results/{agent_mode}/solar-plume.pvsm"
  assert:
    - type: llm-rubric
      subtype: vision
      value: |
          1. Overall Visualization Goal: How well does the result achieve the overall goal of showing tornado flow patterns with glyphs and streamlines?

          2. Glyph Visualization: Does the result show velocity glyphs that are appropriately sized and visible?

          3. Streamline Visualization: Does the result show streamlines that follow the flow patterns effectively?

          4. Tube Rendering: Are the streamlines rendered as tubes with appropriate thickness?

# 6. Supernova Dataset
- vars:
    question: |
        Task:

        Load the supernova dataset from "supernova/data/supernova_256x256x256_float32.raw", the information about this dataset:
        Supernova (Scalar)
        Data Scalar Type: float
        Data Byte Order: little Endian
        Data Spacing: 1x1x1
        Data Extent: 256x256x256
        Data loading is very important, make sure you correctly load the dataset according to their features.

        Then visualize it and extract two isosurfaces. One of them use color red, showing areas with low density (isovalue 40 and opacity 0.4), while the other use color blue, showing areas with high density (isovalue 150 and opacity 0.8).

        Please think step by step and make sure to fulfill all the visualization goals mentioned above. Only make the two isosurfaces visible.

        Finally, save the paraview state as "supernova/results/{agent_mode}/supernova.pvsm"
  assert:
    - type: llm-rubric
      subtype: vision
      value: |
          1. Overall Visualization Goal: How well does the result achieve the overall goal of showing the supernova structure with two distinct isosurfaces representing different density regions?

          2. Does the red isosurface show low density areas (outside regions) with lower opacity?

          3. Does the blue isosurface show high density areas (inside regions) with higher opacity?

# 7. Tangaroa Dataset
- vars:
    question: |
        Task:

        Load the tangaroa dataset from "tangaroa_300x180x120_float32_scalar3.raw", the information about this dataset:
        tangaroa (Vector)
        Data Scalar Type: float
        Data Byte Order: little Endian
        Data Extent: 300x180x120
        Number of Scalar Components: 3
        Data loading is very important, make sure you correctly load the dataset according to their features.

        Apply "streamline tracer" filter, set the "Seed Type" to point cloud, turn off the "show sphere", set the center to [81.6814, 80.708, 23.5093], and radius to 29.9

        Add "Ribbon" filter to the streamline tracer results and set width to 0.3, set the Display representation to Surface.

        In pipeline browser panel, hide everything except the ribbon filter results.

        Please think step by step and make sure to fulfill all the visualization goals mentioned above.

        Finally, save the paraview state as "tangaroa/results/{agent_mode}/tangaroa.pvsm"
  assert:
    - type: llm-rubric
      subtype: vision
      value: |
          1. Overall Visualization Goal: How well does the result reveal the tangaroa flow structures using streamlines expanded into surfaces with the Ribbon filter?

          2. Streamline Seeding: Are streamlines correctly seeded from a Point Cloud centered at [81.6814, 80.708, 23.5093] with radius 29.9, and is the seed sphere hidden?

          3. Ribbon Visualization: Are the streamlines rendered with the Ribbon filter, set to width 0.3, with Display representation as Surface, effectively showing flow surfaces?

# 8. Tornado Dataset
- vars:
    question: |
        Task:

        Load the tornado dataset from "tornado/data/tornado_64x64x64_float32_scalar3.raw", the information about this dataset:
        Tornado (Vector)
        Data Scalar Type: float
        Data Byte Order: little Endian
        Data Extent: 64x64x64
        Number of Scalar Components: 3
        Data loading is very important, make sure you correctly load the dataset according to their features.

        Add a "glyph" filter under the tornado data to display velocity glyph, set an appropriate "Scale Factor" so the glyphs are visible.

        Then add a "stream tracer" filter under the tornado data to generate streamlines. Choose "Point Cloud" as "Seed Type", and do not show sphere.

        Add a "tube" filter under the stream tracer you just created to generate tubes for visualizing the streamlines. Set an appropriate radius. Make the stream tracer invisible and the tube visible. At last, render the streamlines as tubes.

        Please think step by step and make sure to fulfill all the visualization goals mentioned above.

        Finally, save the paraview state as "tornado/results/{agent_mode}/tornado.pvsm"
  assert:
    - type: llm-rubric
      subtype: vision
      value: |
          1. Overall Visualization Goal: How well does the result achieve the overall goal of showing tornado flow patterns with glyphs and streamlines?

          2. Glyph Visualization: Does the result show velocity glyphs that are appropriately sized and visible?

          3. Streamline Visualization: Does the result show streamlines that follow the flow patterns effectively?

          4. Tube Rendering: Are the streamlines rendered as tubes with appropriate thickness?

# 9. Vortex Dataset
- vars:
    question: |
        Task:

        Load the vortex dataset from "vortex/data/vortex_128x128x128_float32.raw", the information about this dataset:
        vortex (Scalar)
        Data Scalar Type: float
        Data Byte Order: little Endian
        Data Extent: 128x128x128
        Number of Scalar Components: 1

        Instructions:

        1. Load the dataset into ParaView.

        2. Leverage "contour" filter to achieve iso-surface rendering. In pipeline browser panel, hide everything except the "contour" fileter.

        3. In properties panel of "contour" filter, set isosurface value to -0.2, use Solid Color and set the color as beige.

        4. Enable Ambient occlusion by toggle the "Use Ambient Occlusion" button in the Render Passes.

        5. Add head light with light inspector, set "Coords" as Camera, "Intentsity" to 0.2, Type to "Directional".

        6. Save your work:
        Save the ParaView state as "vortex/results/{agent_mode}/vortex.pvsm".
  assert:
    - type: llm-rubric
      subtype: vision
      value: |
          1. Overall Visualization Goal: How well does the result present a clear iso-surface rendering of the vortex scalar field at value −0.2?

          2. Contour Appearance: Is the contour rendered with Solid Color set to beige and made the only visible object in the pipeline?

          3. Lighting & Shading: Are Ambient Occlusion and a directional head light (Coords = Camera, Intensity = 0.2) applied?

# 10. Foot Dataset
- vars:
    question: |
        Task:

        Load the Foot dataset from "foot/data/foot_256x256x256_uint8.raw", the information about this dataset:
        Foot
        Description: Rotational C-arm x-ray scan of a human foot. Tissue and bone are present in the dataset.
        Data Type: uint8
        Data Byte Order: little Endian
        Data Spacing: 1x1x1
        Data Extent: 256x256x256
        Data loading is very important, make sure you correctly load the dataset according to their features.

        Visualize the anatomical structures:
        1. Apply volume rendering with an X-ray transfer function that distinguishes soft tissues and bones. Bones with darker color, and soft tissue with lighter color.

        2. Analyze the visualization and answer the following questions:

        Q1: Based on the X-ray style volume rendering of the foot dataset, which of the following best describes the visibility of bony structures?
        A. Both the phalanges and metatarsals are fully visible
        B. The phalanges are fully visible, but the metatarsals are only partially visible
        C. The metatarsals are fully visible, but the phalanges are only partially visible
        D. Neither the phalanges nor the metatarsals are clearly visible

        3. Save your work:
        Save the ParaView state as "foot/results/{agent_mode}/foot.pvsm".
        Save the answers to the analysis questions in plain text as "foot/results/{agent_mode}/answers.txt".
  assert:
    - type: llm-rubric
      subtype: vision
      value: |
          1. Overall Goal: Does the visualization effectively distinguish between different tissue types in the foot dataset?

          2. X-ray Appearance: Does the visualization resemble an X-ray (monochrome or grayscale, transparent look, consistent lighting)?

    - type: llm-rubric
      subtype: text
      value: |
          1. Q1 correct answer: B. The phalanges are fully visible, but the metatarsals are only partially visible

# 11. Lobster Dataset
- vars:
    question: |
        Task:

        Load the Lobster dataset from "lobster/data/lobster_301x324x56_uint8.raw", the information about this dataset:
        Lobster
        Description: CT scan of a lobster contained in a block of resin.
        Data Type: uint8
        Data Byte Order: little Endian
        Data Spacing: 1x1x1.4
        Data Extent: 301x324x56
        Data loading is very important, make sure you correctly load the dataset according to their features.

        Visualize the scanned specimen:
        1. Create an isosurface at the specimen boundary, find a proper isovalue to show the whole structure.

        2. Use natural colors appropriate for the specimen (red-orange for lobster)

        3. Analyze the visualization and answer the following questions:

        Q1: Based on the isosurface visualization of the lobster specimen, how many walking legs are visible?
        A. 6 walking legs
        B. 7 walking legs
        C. 8 walking legs
        D. 10 walking legs

        4. Save your work:
        Save the ParaView state as "lobster/results/{agent_mode}/lobster.pvsm".
        Save the answers to the analysis questions in plain text as "lobster/results/{agent_mode}/answers.txt".
  assert:
    - type: llm-rubric
      subtype: vision
      value: |
          1. Overall Goal: Does the visualization clearly show the structure and details of the Lobster?

          2. Boundary Clearity: Are surface details and boundaries of the lobster well-defined?

          3. Correct Color: Is the color of the lobster mimic a real one? (red-orange)

    - type: llm-rubric
      subtype: text
      value: |
          1. Q1 correct answer: B. 7 walking legs

# 12. Chameleon Dataset (IsoSurface)
- vars:
    question: |
        Task:
        Load the chameleon dataset from "chameleon_isosurface/data/chameleon_isosurface_256x256x256_float32.vtk".
        Generate a visualization image of 2 isosurfaces of the Chameleon scalar field dataset with the following visualization settings:
        1) Create isosurfaces of Iso_1 with a value of 0.12 and Iso_2 with a value of 0.45
        2) Assign RGB color of [0.0, 1.0, 0.0] to Iso_1, and color of [1.0, 1.0, 1.0] to Iso_2
        3) Assign opacity of 0.1 to Iso_1, and opacity of 0.99 to Iso_2
        4) Set the lighting parameter as: 0.1 to Ambient; 0.7 to Diffuse; 0.6 to Specular
        5) Set the viewpoint parameters as: [600, 0, 0] to position; [0, 0, 0] to focal point; [0, -1, 0] to camera up direction
        6) White background
        7) Visualization image resolution is 1024x1024
        8) Save the visualization image as a png file "chameleon_isosurface/results/{agent_mode}/chameleon_isosurface.png"
        9) (Option 1) Save the paraview state as "chameleon_isosurface/results/{agent_mode}/chameleon_isosurface.pvsm" if you are using ParaView as the visualization tool
        10) (Option 2) Save the cxx code script as "chameleon_isosurface/results/{agent_mode}/chameleon_isosurface.cxx" if you are using VTK as the visualization tool
  assert:
    - type: llm-rubric
      subtype: vision
      value: |
          1. Overall Visualization Goal: Does the result present a good isosurface rendering compared to groundtruth?
          
          2. Is the skin of the Chameleon object of green color?
          
          3. Is the bone of the Chameleon object of white color?


# 13. Argon Bubble
# A CFD simulation of a bubble of argon gas immersed in air and being hit by a shockwave. 
# This dataset is a time-varying volume dataset created by the Center for Computational Sciences and Engineering (CCSE) at Lawrence Berkeley National Laboratory.
# The volumetric used for the SciVis benchmark is one frame of the time sequence.
- vars:
    question: |
        Task:
        Load the Argon Bubble dataset from "argon-bubble/data/argon-bubble_128x128x256_float32.vtk".
        Generate a visualization image of the Argon Bubble scalar field dataset with the following visualization settings:
        1) Create volume rendering
        2) Set the opacity transfer function as a ramp function across values of the volumetric data, assigning opacity 0 to value 0 and assigning opacity 1 to value 1.
        3) Set the color transfer function to assign a warm red color [0.71, 0.02, 0.15] to the highest value, a cool color [0.23, 0.29, 0.75] to the lowest value, and a grey color[0.87, 0.87, 0.87] to the midrange value
        4) Set the viewpoint parameters as: [0, 450, 0] to position; [0, 0, -15] to focal point; [0, 0, -1] to camera up direction
        5) Visualization image resolution is 1024x1024. White background. Shade turned off. Volume rendering ray casting sample distance is 0.1
        6) Save the visualization image as a png file "argon-bubble/results/{agent_mode}/argon-bubble.png"
        7) (Option 1) Save the paraview state as "argon-bubble/results/{agent_mode}/argon-bubble.pvsm" if you are using ParaView as the visualization tool
        8) (Option 2) Save the cxx code script as "argon-bubble/results/{agent_mode}/argon-bubble.cxx" if you are using VTK as the visualization tool
  assert:
    - type: llm-rubric
      subtype: vision
      value: |
          1. Does the visualization image clearly show the regions of cool, warm, and mild regions?

          2. Does the blueish region show areas with low opacity?

          3. Does the reddish region show areas with high opacity?


# 14. Richtmyer-Meshkov Instability Simulation
# Entropy field (timestep 160) of Richtmyer-Meshkov instability simulation
- vars:
    question: |
        Task:
        Load the Richtmyer dataset from "richtmyer/data/richtmyer_256x256x240_float32.vtk".
        Generate a visualization image of the Richtmyer dataset, Entropy field (timestep 160) of Richtmyer-Meshkov instability simulation, with the following visualization settings: 
        1) Create volume rendering
        2) Set the opacity transfer function as a ramp function from value 0.05 to 1 of the volumetric data, assigning opacity 0 to value less than 0.05 and assigning opacity 1 to value 1.
        3) Set the color transfer function following the 7 rainbow colors and assign a red color [1.0, 0.0, 0.0] to the highest value, a purple color [0.5, 0.0, 1.0] to the lowest value.
        4) Visualization image resolution is 1024x1024
        5) Set the viewpoint parameters as: [420, 420, -550] to position; [128, 128, 150] to focal point; [-1, -1, 1] to camera up direction
        6) Turn on the shade and set the ambient, diffuse and specular as 1.0
        7) White background. Volume rendering ray casting sample distance is 0.1
        8) Save the visualization image as a png file "richtmyer/results/{agent_mode}/richtmyer.png"
        9) (Option 1) Save the paraview state as "richtmyer/results/{agent_mode}/richtmyer.pvsm" if you are using ParaView as the visualization tool
        10) (Option 2) Save the cxx code script as "richtmyer/results/{agent_mode}/richtmyer.cxx" if you are using VTK as the visualization tool
  assert:
    - type: llm-rubric
      subtype: vision
      value: |
          1. Does the visualization show a clear surface with peaks and valleys?

          2. Are the peaks highlighted with the color yellow?

          3. Are the valleys highlighted with the color blue?


# 15. Rayleigh-Taylor Instability (Miranda)
# A time step of a density field in a simulation of the mixing transition in Rayleigh-Taylor instability
- vars:
    question: |
        Task:
        Load the Rayleigh-Taylor Instability dataset from "miranda/data/miranda_256x256x256_float32.vtk".
        Generate a visualization image of the Rayleigh-Taylor Instability dataset, a time step of a density field in a simulation of the mixing transition in Rayleigh-Taylor instability, with the following visualization settings:
        1) Create volume rendering
        2) Set the opacity transfer function as a ramp function from value 0 to 1 of the volumetric data, assigning opacity 0 to value 0 and assigning opacity 1 to value 1.
        3) Set the color transfer function following the 7 rainbow colors and assign a red color [1.0, 0.0, 0.0] to the highest value, a purple color [0.5, 0.0, 1.0] to the lowest value.
        4) Set the viewpoint parameters as: [650, 650, 650] to position; [128, 128, 128] to focal point; [1, 0, 0] to camera up direction
        5) Volume rendering ray casting sample distance is 0.1
        6) White background
        7) Visualization image resolution is 1024x1024
        8) Save the visualization image as a png file "miranda/results/{agent_mode}/miranda.png"
        9) (Option 1) Save the paraview state as "miranda/results/{agent_mode}/miranda.pvsm" if you are using ParaView as the visualization tool
        10) (Option 2) Save the cxx code script as "miranda/results/{agent_mode}/miranda.cxx" if you are using VTK as the visualization tool
  assert:
    - type: llm-rubric
      subtype: vision
      value: |
          1. Does the visualization image clearly show the regions from low to high intensity?

          2. Does the purple region show areas with low opacity?

          3. Does the red region show areas with high opacity?


# 16. Rotstrat
# Temperature field of a direct numerical simulation of rotating stratified turbulence
- vars:
    question: |
        Task:
        Load the rotstrat dataset from "rotstrat/data/rotstrat_256x256x256_float32.vtk".
        Generate a visualization image of the Rotstrat dataset, temperature field of a direct numerical simulation of rotating stratified turbulence, with the following visualization settings: 
        1) Create volume rendering
        2) Set the opacity transfer function as a step function jumping from 0 to 1 at value 0.12
        3) Set the color transfer function to assign a warm red color [0.71, 0.02, 0.15] to the highest value, a cool color [0.23, 0.29, 0.75] to the lowest value, and a grey color[0.87, 0.87, 0.87] to the midrange value
        4) Set the viewpoint parameters as: [800, 128, 128] to position; [0, 128, 128] to focal point; [0, 1, 0] to camera up direction
        5) Volume rendering ray casting sample distance is 0.1
        6) White background
        7) Visualization image resolution is 1024x1024
        8) Save the visualization image as a png file "rotstrat/results/{agent_mode}/rotstrat.png"
        9) (Option 1) Save the paraview state as "rotstrat/results/{agent_mode}/rotstrat.pvsm" if you are using ParaView as the visualization tool
        10) (Option 2) Save the cxx code script as "rotstrat/results/{agent_mode}/rotstrat.cxx" if you are using VTK as the visualization tool
  assert:
    - type: llm-rubric
      subtype: vision
      value: |
          1. Does the visualization image clearly show the shape of turbulence compared to ground truth?

          2. Does the blueish region show areas with low opacity?

          3. Does the reddish region show areas with high opacity?