# Comprehensive Test Cases for SciVisAgentBench Main Tasks
# This test evaluates the ability to complete specific visualization tasks
# with detailed requirements and evaluation criteria

# 1. Bonsai Dataset
- vars:
    question: |
        Task:

        Load the bonsai dataset from "bonsai/data/bonsai_256x256x256_uint8.raw", the information about this dataset:
        Bonsai (Scalar)
        Data Scalar Type: unsigned char
        Data Byte Order: little Endian
        Data Spacing: 1x1x1
        Data Extent: 256x256x256

        Then visualize it with volume rendering, modify the transfer function and reach the visualization goal as: "A potted tree with brown pot silver branch and golden leaves."

        Please think step by step and make sure to fulfill all the visualization goals mentioned above.

        Finally, save the paraview state as "bonsai/results/{agent_mode}/bonsai.pvsm"
  assert:
    - type: llm-rubric
      subtype: vision
      value: |
          1. Brown Pot Visualization: Does the result show the pot portion in brown color?

          2. Silver Branch Visualization: Does the result show the branch/trunk portion in silver color?

          3. Golden Leaves Visualization: Does the result show the leaves portion in golden color?

# 2. Carp Dataset
- vars:
    question: |
        Task:

        Load the carp dataset from "carp/data/carp_256x256x512_uint16.raw", the information about this dataset:
        Carp (Scalar)
        Data Scalar Type: unsigned short
        Data Byte Order: little Endian
        Data Spacing: 0.78125x0.390625x1
        Data Extent: 256x256x512

        Instructions:

        1. Load the dataset into ParaView.

        2. Apply volume rendering to visualize the carp skeleton.

        3. Adjust the transfer function to highlight only the bony structures in an X-ray style (suppressing soft tissue).

        4. Optimize the viewpoint to display the full skeleton, ensuring the head, spine, and fins are all clearly visible in a single frame.

        5. Analyze the visualization and answer the following questions:

        Q1: Which of the following options correctly describes the fins visible in the carp skeleton visualization?
        A. 5 fins: 1 dorsal, 2 pectoral, 2 pelvic
        B. 6 fins: 1 dorsal, 2 pectoral, 2 pelvic, 1 caudal
        C. 7 fins: 1 dorsal, 2 pectoral, 2 pelvic, 1 anal, 1 caudal
        D. 8 fins: 2 dorsal, 2 pectoral, 2 pelvic, 1 anal, 1 caudal

        Q2: Based on the visualization, what is the approximate ratio of skull length to total body length?
        A. ~15%
        B. ~22%
        C. ~30%
        D. ~40%

        6. Save your work:
        Save the ParaView state as "carp/results/{agent_mode}/carp.pvsm".
        Save the answers to the analysis questions in plain text as "carp/results/{agent_mode}/answers.txt".
  assert:
    - type: llm-rubric
      subtype: vision
      value: |
          1. Bone Isolation: Are the bones clearly visible while soft tissue and background are suppressed? Thin fin rays should be distinguishable without major loss.

          2. Viewpoint Selection: Does the chosen viewpoint display the entire carp skeleton (head, spine, ribs, fins, tail) without critical occlusion?

          3. X-ray Appearance: Does the visualization resemble an X-ray (monochrome or grayscale, transparent look, consistent lighting)?

          4. Correct Data Setup: Was the dataset loaded with proper spacing (0.78125x0.390625x1.0)? The carp skeleton should appear in its correct proportions without distortion (i.e., the fish shape looks anatomically normal).
    - type: llm-rubric
      subtype: text
      value: |
          1. Q1 correct answer: C. 7 fins: 1 dorsal, 2 pectoral, 2 pelvic, 1 anal, 1 caudal

          2. Q2 correct answer: B. ~22%

# 3. Chameleon Dataset
- vars:
    question: |
        Task:

        Load the chameleon dataset from "chameleon/data/chameleon_256x256x270_float32.raw", the information about this dataset:
        chameleon (Scalar)
        Data Scalar Type: float
        Data Byte Order: little Endian
        Data Extent: 256x256x270
        Number of Scalar Components: 1
        Data loading is very important, make sure you correctly load the dataset according to their features.

        Apply the volume rendering to visualize the chameleon dataset

        Adjust the transfer function to highlight the bony structures and skin in an X-ray style.

        Adjust the camera position and focus on the head part of the chameleon

        Please think step by step and make sure to fulfill all the visualization goals mentioned above.

        Finally, save the paraview state as "chameleon/results/{agent_mode}/chameleon.pvsm"
  assert:
    - type: llm-rubric
      subtype: vision
      value: |
          1. Overall Visualization Goal: Does the result present a clean, X-ray–style volume rendering where the chameleon's bony structures are clearly emphasized and soft tissue is faint but discernible?

          2. Data Loading Correctness: Is the RAW volume loaded with the specified metadata (float32, little-endian, 256×256×270, 1 component) so that the histogram looks reasonable and the anatomy is not flipped or distorted?

          3. Transfer Function Quality: Does the grayscale transfer function make low-intensity tissue mostly transparent while assigning higher opacity to bones/skin ridges, yielding good depth cues without over-saturation or banding?

          4. Camera & Framing: Is the camera positioned and zoomed to focus on the chameleon's head, keeping it sharply framed (no clipping), with a stable viewpoint that highlights key anatomical details?

# 4. Engine Dataset
- vars:
    question: |
        Task:

        Load the vortex dataset from "engine/data/engine_256x256x128_uint8.raw", the information about this dataset:
        engine (Scalar)
        Data Scalar Type: float
        Data Byte Order: little Endian
        Data Extent: 256x256x128
        Number of Scalar Components: 1

        Instructions:

        1. Load the dataset into ParaView.

        2. Apply the volume rendering to visualize the engine dataset

        3. Adjust the transfer function, let the outer part more transparent and the inner part more solid. Use light blue for the outer part and orange for the inner part.

        4. Save your work:
        Save the ParaView state as "engine/results/{agent_mode}/engine.pvsm".
  assert:
    - type: llm-rubric
      subtype: vision
      value: |
          1. Overall Visualization Goal: How well does the result use volume rendering to clearly present the internal and external structures of the engine dataset?

          2. Structural Clarity: Does the visualization emphasize depth so that the outer layers do not obscure the inner structures?

          3. Transfer Function Transparency: Is the outer region rendered with higher transparency and the inner region more solid, achieving a clear layering effect?

          4. Transfer Function Color Mapping: Are colors correctly assigned so that the outer part is light blue and the inner part is orange, enhancing structural contrast?

# 5. Solar Plume Dataset
- vars:
    question: |
        Task:

        Load the tornado dataset from "solar-plume/data/solar-plume_126x126x512_float32_scalar3.raw", the information about this dataset:
        solar-plume (Vector)
        Data Scalar Type: float
        Data Byte Order: little Endian
        Data Extent: 126x126x512
        Number of Scalar Components: 3
        Data loading is very important, make sure you correctly load the dataset according to their features.

        Add a "stream tracer" filter under the tornado data to display streamline, set the "Seed type" to "Point Cloud" and set the center of point cloud to 3D position [50, 50, 320] with a radius 30, then hide the point cloud sphere.

        Add a "tube" filter under the "stream tracer" filter to enhance the streamline visualization. Set the radius to 0.5. In the pipeline browser panel, hide everything except the "tube" filter. 


        Please think step by step and make sure to fulfill all the visualization goals mentioned above.

        Finally, save the paraview state as "solar-plume/results/{agent_mode}/solar-plume.pvsm"
  assert:
    - type: llm-rubric
      subtype: vision
      value: |
          1. Overall Visualization Goal: How well does the result achieve the overall goal of showing tornado flow patterns with glyphs and streamlines?

          2. Glyph Visualization: Does the result show velocity glyphs that are appropriately sized and visible?

          3. Streamline Visualization: Does the result show streamlines that follow the flow patterns effectively?

          4. Tube Rendering: Are the streamlines rendered as tubes with appropriate thickness?

# 6. Supernova Dataset
- vars:
    question: |
        Task:

        Load the supernova dataset from "supernova/data/supernova_256x256x256_float32.raw", the information about this dataset:
        Supernova (Scalar)
        Data Scalar Type: float
        Data Byte Order: little Endian
        Data Spacing: 1x1x1
        Data Extent: 256x256x256
        Data loading is very important, make sure you correctly load the dataset according to their features.

        Then visualize it and extract two isosurfaces. One of them use color red, showing areas with low density (isovalue 40 and opacity 0.4), while the other use color blue, showing areas with high density (isovalue 150 and opacity 0.8).

        Please think step by step and make sure to fulfill all the visualization goals mentioned above. Only make the two isosurfaces visible.

        Finally, save the paraview state as "supernova/results/{agent_mode}/supernova.pvsm"
  assert:
    - type: llm-rubric
      subtype: vision
      value: |
          1. Overall Visualization Goal: How well does the result achieve the overall goal of showing the supernova structure with two distinct isosurfaces representing different density regions?

          2. Does the red isosurface show low density areas (outside regions) with lower opacity?

          3. Does the blue isosurface show high density areas (inside regions) with higher opacity?

# 7. Tangaroa Dataset
- vars:
    question: |
        Task:

        Load the tangaroa dataset from "tangaroa_300x180x120_float32_scalar3.raw", the information about this dataset:
        tangaroa (Vector)
        Data Scalar Type: float
        Data Byte Order: little Endian
        Data Extent: 300x180x120
        Number of Scalar Components: 3
        Data loading is very important, make sure you correctly load the dataset according to their features.

        Apply "streamline tracer" filter, set the "Seed Type" to point cloud, turn off the "show sphere", set the center to [81.6814, 80.708, 23.5093], and radius to 29.9

        Add "Ribbon" filter to the streamline tracer results and set width to 0.3, set the Display representation to Surface.

        In pipeline browser panel, hide everything except the ribbon filter results.

        Please think step by step and make sure to fulfill all the visualization goals mentioned above.

        Finally, save the paraview state as "tangaroa/results/{agent_mode}/tangaroa.pvsm"
  assert:
    - type: llm-rubric
      subtype: vision
      value: |
          1. Overall Visualization Goal: How well does the result reveal the tangaroa flow structures using streamlines expanded into surfaces with the Ribbon filter?

          2. Streamline Seeding: Are streamlines correctly seeded from a Point Cloud centered at [81.6814, 80.708, 23.5093] with radius 29.9, and is the seed sphere hidden?

          3. Ribbon Visualization: Are the streamlines rendered with the Ribbon filter, set to width 0.3, with Display representation as Surface, effectively showing flow surfaces?

# 8. Tornado Dataset
- vars:
    question: |
        Task:

        Load the tornado dataset from "tornado/data/tornado_64x64x64_float32_scalar3.raw", the information about this dataset:
        Tornado (Vector)
        Data Scalar Type: float
        Data Byte Order: little Endian
        Data Extent: 64x64x64
        Number of Scalar Components: 3
        Data loading is very important, make sure you correctly load the dataset according to their features.

        Add a "glyph" filter under the tornado data to display velocity glyph, set an appropriate "Scale Factor" so the glyphs are visible.

        Then add a "stream tracer" filter under the tornado data to generate streamlines. Choose "Point Cloud" as "Seed Type", and do not show sphere.

        Add a "tube" filter under the stream tracer you just created to generate tubes for visualizing the streamlines. Set an appropriate radius. Make the stream tracer invisible and the tube visible. At last, render the streamlines as tubes.

        Please think step by step and make sure to fulfill all the visualization goals mentioned above.

        Finally, save the paraview state as "tornado/results/{agent_mode}/tornado.pvsm"
  assert:
    - type: llm-rubric
      subtype: vision
      value: |
          1. Overall Visualization Goal: How well does the result achieve the overall goal of showing tornado flow patterns with glyphs and streamlines?

          2. Glyph Visualization: Does the result show velocity glyphs that are appropriately sized and visible?

          3. Streamline Visualization: Does the result show streamlines that follow the flow patterns effectively?

          4. Tube Rendering: Are the streamlines rendered as tubes with appropriate thickness?

# 9. Vortex Dataset
- vars:
    question: |
        Task:

        Load the vortex dataset from "vortex/data/vortex_128x128x128_float32.raw", the information about this dataset:
        vortex (Scalar)
        Data Scalar Type: float
        Data Byte Order: little Endian
        Data Extent: 128x128x128
        Number of Scalar Components: 1

        Instructions:

        1. Load the dataset into ParaView.

        2. Leverage "contour" filter to achieve iso-surface rendering. In pipeline browser panel, hide everything except the "contour" fileter.

        3. In properties panel of "contour" filter, set isosurface value to -0.2, use Solid Color and set the color as beige.

        4. Enable Ambient occlusion by toggle the "Use Ambient Occlusion" button in the Render Passes.

        5. Add head light with light inspector, set "Coords" as Camera, "Intentsity" to 0.2, Type to "Directional".

        6. Save your work:
        Save the ParaView state as "vortex/results/{agent_mode}/vortex.pvsm".
  assert:
    - type: llm-rubric
      subtype: vision
      value: |
          1. Overall Visualization Goal: How well does the result present a clear iso-surface rendering of the vortex scalar field at value −0.2?

          2. Contour Appearance: Is the contour rendered with Solid Color set to beige and made the only visible object in the pipeline?

          3. Lighting & Shading: Are Ambient Occlusion and a directional head light (Coords = Camera, Intensity = 0.2) applied?

# 10. Foot Dataset
- vars:
    question: |
        Task:

        Load the Foot dataset from "foot/data/foot_256x256x256_uint8.raw", the information about this dataset:
        Foot
        Description: Rotational C-arm x-ray scan of a human foot. Tissue and bone are present in the dataset.
        Data Type: uint8
        Data Byte Order: little Endian
        Data Spacing: 1x1x1
        Data Extent: 256x256x256
        Data loading is very important, make sure you correctly load the dataset according to their features.

        Visualize the anatomical structures:
        1. Apply volume rendering with an X-ray transfer function that distinguishes soft tissues and bones. Bones with darker color, and soft tissue with lighter color.

        2. Analyze the visualization and answer the following questions:

        Q1: Based on the X-ray style volume rendering of the foot dataset, which of the following best describes the visibility of bony structures?
        A. Both the phalanges and metatarsals are fully visible
        B. The phalanges are fully visible, but the metatarsals are only partially visible
        C. The metatarsals are fully visible, but the phalanges are only partially visible
        D. Neither the phalanges nor the metatarsals are clearly visible

        3. Save your work:
        Save the ParaView state as "foot/results/{agent_mode}/foot.pvsm".
        Save the answers to the analysis questions in plain text as "foot/results/{agent_mode}/answers.txt".
  assert:
    - type: llm-rubric
      subtype: vision
      value: |
          1. Overall Goal: Does the visualization effectively distinguish between different tissue types in the foot dataset?

          2. X-ray Appearance: Does the visualization resemble an X-ray (monochrome or grayscale, transparent look, consistent lighting)?

    - type: llm-rubric
      subtype: text
      value: |
          1. Q1 correct answer: B. The phalanges are fully visible, but the metatarsals are only partially visible

# 11. Lobster Dataset
- vars:
    question: |
        Task:

        Load the Lobster dataset from "lobster/data/lobster_301x324x56_uint8.raw", the information about this dataset:
        Lobster
        Description: CT scan of a lobster contained in a block of resin.
        Data Type: uint8
        Data Byte Order: little Endian
        Data Spacing: 1x1x1.4
        Data Extent: 301x324x56
        Data loading is very important, make sure you correctly load the dataset according to their features.

        Visualize the scanned specimen:
        1. Create an isosurface at the specimen boundary, find a proper isovalue to show the whole structure.

        2. Use natural colors appropriate for the specimen (red-orange for lobster)

        3. Analyze the visualization and answer the following questions:

        Q1: Based on the isosurface visualization of the lobster specimen, how many walking legs are visible?
        A. 6 walking legs
        B. 7 walking legs
        C. 8 walking legs
        D. 10 walking legs

        4. Save your work:
        Save the ParaView state as "lobster/results/{agent_mode}/lobster.pvsm".
        Save the answers to the analysis questions in plain text as "lobster/results/{agent_mode}/answers.txt".
  assert:
    - type: llm-rubric
      subtype: vision
      value: |
          1. Overall Goal: Does the visualization clearly show the structure and details of the Lobster?

          2. Boundary Clearity: Are surface details and boundaries of the lobster well-defined?

          3. Correct Color: Is the color of the lobster mimic a real one? (red-orange)

    - type: llm-rubric
      subtype: text
      value: |
          1. Q1 correct answer: B. 7 walking legs